<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*       on 2022-06-27T09:47:38-06:00       *-->
<!--*   A recent stable commit (2020-08-09):   *-->
<!--* 98f21740783f166a773df4dc83cab5293ab63a4a *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Eigenvalues and Eigenvectors</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="Linear Algebra">
<meta property="book:author" content="Sean Fitzpatrick">
<script src="https://sagecell.sagemath.org/static/embedded_sagecell.js"></script><script>window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore|ignore-math",
    processHtmlClass: "process-math",
    renderActions: {
        findScript: [10, function (doc) {
            document.querySelectorAll('script[type^="math/tex"]').forEach(function(node) {
                var display = !!node.type.match(/; *mode=display/);
                var math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                var text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = {node: text, delim: '', n: 0};
                math.end = {node: text, delim: '', n: 0};
                doc.math.push(math);
            });
        }, '']
    },
  },
  chtml: {
    scale: 0.88,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/themes/prism.css" rel="stylesheet">
<script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.13/pretext.js"></script><script>miniversion=0.674</script><script src="https://pretextbook.org/js/0.13/pretext_add_on.js?x=1"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<script src="https://cdn.geogebra.org/apps/deployggb.js"></script><link href="https://pretextbook.org/css/0.4/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/colors_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/setcolors.css" rel="stylesheet" type="text/css">
<script type="text/javascript">
eBookConfig = {};
eBookConfig.useRunestoneServices = true;
eBookConfig.host = '';
eBookConfig.app = eBookConfig.host + '/runestone';
eBookConfig.course = '~._ course_name _.~';
eBookConfig.basecourse = '~._ base_course _.~';
eBookConfig.isLoggedIn = ~._ is_logged_in _.~;
eBookConfig.email = '~._ user_email _.~';
eBookConfig.isInstructor = ~._ is_instructor _.~;
eBookConfig.logLevel = 10;
eBookConfig.ajaxURL = eBookConfig.app + "/ajax/";
eBookConfig.username = '~._ user_id _.~';
eBookConfig.readings = ~._ readings|safe _.~;
eBookConfig.activities = ~._ activity_info|safe _.~;
eBookConfig.downloadsEnabled = ~._ downloads_enabled _.~;
eBookConfig.allow_pairs = ~._ allow_pairs _.~;
eBookConfig.enableScratchAC = false;
eBookConfig.new_server_prefix = "/ns";
</script>

{% if serve_ad and settings.adsenseid %}
<script data-ad-client="~._ settings.adsenseid _.~" async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
{% endif %}
<script type="text/javascript" src="https://www.youtube.com/player_api"></script><style>.dropdown {
    position: relative;
    display: inline-block;
    height: 39px;
    width: 50px;
    margin-left: auto;
    margin-right: auto;
    padding: 7px;
    text-align: center;
    background-color: #eeeeee;
    border: 1px solid;
    border-color: #aaaaaa;
 }
 .dropdown-content {
    position: absolute;
    display: none;
    left: 300px;
    text-align: left;
    font-family: 'Open Sans', 'Helvetica Neue', 'Helvetica';
}
.dropdown:hover {
    background-color: #ddd;
}
.dropdown:hover .dropdown-content {
    display: block;
    position: fixed;
}
.dropdown-content {
    background-color: white;
    z-index: 1800;
    min-width: 100px;
    padding: 5px;
}
.dropdown-content a {
    display: block;
    text-decoration: none;
    color: #662211;
}
.dropdown-content a:hover {
    background-color: #671d12;
    color: #ffffff;
}
</style>
<!--*** Runestone Services ***-->
<script type="text/javascript" src="_static/runtime.b0f8547c48f16a9f.bundle.js"></script><script type="text/javascript" src="_static/637.d54be67956c5c660.bundle.js"></script><script type="text/javascript" src="_static/runestone.0e9550fe42760516.bundle.js"></script><link rel="stylesheet" type="text/css" href="_static/637.fafafbd97df8a0d1.css">
<link rel="stylesheet" type="text/css" href="_static/runestone.e4d5592da655219f.css">
</head>
<body class="pretext-book ignore-math has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\newcommand{\spn}{\operatorname{span}}
\newcommand{\bbm}{\begin{bmatrix}}
\newcommand{\ebm}{\end{bmatrix}}
\newcommand{\R}{\mathbb{R}}
\ifdefined\C
\renewcommand\C{\mathbb{C}}
\else
\newcommand\C{\mathbb{C}}
\fi
\newcommand{\im}{\operatorname{im}}
\newcommand{\nll}{\operatorname{null}}
\newcommand{\csp}{\operatorname{col}}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\diag}{\operatorname{diag}}
\newcommand{\tr}{\operatorname{tr}}
\newcommand{\dotp}{\!\boldsymbol{\cdot}\!}
\newcommand{\len}[1]{\lVert #1\rVert}
\newcommand{\abs}[1]{\lvert #1\rvert}
\newcommand{\proj}[2]{\operatorname{proj}_{#1}{#2}}
\newcommand{\bz}{\overline{z}}
\newcommand{\zz}{\mathbf{z}}
\newcommand{\uu}{\mathbf{u}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\ww}{\mathbf{w}}
\newcommand{\xx}{\mathbf{x}}
\newcommand{\yy}{\mathbf{y}}
\newcommand{\zer}{\mathbf{0}}
\newcommand{\vecq}{\mathbf{q}}
\newcommand{\vecp}{\mathbf{p}}
\newcommand{\vece}{\mathbf{e}}
\newcommand{\basis}[2]{\{\mathbf{#1}_1,\mathbf{#1}_2,\ldots,\mathbf{#1}_{#2}\}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="linear-algebra.html"><span class="title">Linear Algebra:</span> <span class="subtitle">A second course, featuring proofs and Python</span></a></h1>
<p class="byline">Sean Fitzpatrick</p>
</div>
</div></div>
<nav id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3">
<button id="calculator-toggle" class="toolbar-item button toggle" title="Show calculator" aria-expanded="false" aria-controls="calculator-container">Calc</button><div id="calculator-container" class="calculator-container" style="display: none; z-index:100;"><div id="geogebra-calculator"></div></div>
<script>
var ggbApp = new GGBApplet({"appName": "graphing",
    "width": 330,
    "height": 600,
    "showToolBar": true,
    "showAlgebraInput": true,
    "perspective": "G/A",
    "algebraInputPosition": "bottom",
    "scaleContainerClass": "calculator-container",
    "allowUpscale": true,
    "autoHeight": true,
    "disableAutoScale": false},
true);
</script><div class="dropdown">ðŸ‘¤<div class="dropdown-content">
{% if settings.academy_mode: %}
<a href="/runestone/assignments/chooseAssignment">Assignments</a><a href="/runestone/assignments/practice">Practice</a><hr>
<a href="/runestone/default/courses">Change Course</a><hr>
<a id="ip_dropdown_link" href="/runestone/admin/index">Instructor's Page</a><hr>
{% endif %}
<a href="/runestone/dashboard/studentreport">Progress Page</a><hr>
<a href="/runestone/default/user/profile">Edit Profile</a><a href="/runestone/default/user/change_password">Change Password</a><a href="/runestone/default/user/logout">Log Out</a><a href="/runestone/default/user/register">Register</a><a href="/runestone/default/user/login">Login</a><a href="/runestone/assignments/index">Progress Page</a>
</div>
</div>
<span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="ch-diagonalization.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="ch-diagonalization.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="subsec-ortho-diag.html" title="Next">Next</a></span>
</div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="ch-diagonalization.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="ch-diagonalization.html" title="Up">Up</a><a class="next-button button toolbar-item" href="subsec-ortho-diag.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link frontmatter">
<a href="frontmatter-1.html" data-scroll="frontmatter-1" class="internal"><span class="title">Front Matter</span></a><ul>
<li><a href="colophon-1.html" data-scroll="colophon-1" class="internal">Colophon</a></li>
<li><a href="preface-1.html" data-scroll="preface-1" class="internal">Preface</a></li>
</ul>
</li>
<li class="link">
<a href="ch-vector-space.html" data-scroll="ch-vector-space" class="internal"><span class="codenumber">1</span> <span class="title">Vector spaces</span></a><ul>
<li><a href="sec-vec-sp.html" data-scroll="sec-vec-sp" class="internal">Definition and examples</a></li>
<li><a href="sec-vsp-properties.html" data-scroll="sec-vsp-properties" class="internal">Properties</a></li>
<li><a href="sec-subspace.html" data-scroll="sec-subspace" class="internal">Subspaces</a></li>
<li><a href="sec-span.html" data-scroll="sec-span" class="internal">Span</a></li>
<li><a href="worksheet-span.html" data-scroll="worksheet-span" class="internal">Worksheet: understanding span</a></li>
<li><a href="sec-independence.html" data-scroll="sec-independence" class="internal">Linear Independence</a></li>
<li><a href="sec-dimension.html" data-scroll="sec-dimension" class="internal">Basis and dimension</a></li>
<li><a href="sec-subspace-combine.html" data-scroll="sec-subspace-combine" class="internal">New subspaces from old</a></li>
</ul>
</li>
<li class="link">
<a href="ch-linear-trans.html" data-scroll="ch-linear-trans" class="internal"><span class="codenumber">2</span> <span class="title">Linear Transformations</span></a><ul>
<li><a href="sec-lin-tran-intro.html" data-scroll="sec-lin-tran-intro" class="internal">Definition and examples</a></li>
<li><a href="sec-kernel-image.html" data-scroll="sec-kernel-image" class="internal">Kernel and Image</a></li>
<li><a href="sec-isomorphism.html" data-scroll="sec-isomorphism" class="internal">Isomorphisms, composition, and inverses</a></li>
<li><a href="worksheet-transformations.html" data-scroll="worksheet-transformations" class="internal">Worksheet: matrix transformations</a></li>
<li><a href="worksheet-recurrence.html" data-scroll="worksheet-recurrence" class="internal">Worksheet: linear recurrences</a></li>
</ul>
</li>
<li class="link">
<a href="ch-orthogonality.html" data-scroll="ch-orthogonality" class="internal"><span class="codenumber">3</span> <span class="title">Orthogonality and Applications</span></a><ul>
<li><a href="sec-orthogonal-sets.html" data-scroll="sec-orthogonal-sets" class="internal">Orthogonal sets of vectors</a></li>
<li><a href="sec-ortho-projection.html" data-scroll="sec-ortho-projection" class="internal">Orthogonal Projection</a></li>
<li><a href="worksheet-dual-basis.html" data-scroll="worksheet-dual-basis" class="internal">Worksheet: dual basis.</a></li>
</ul>
</li>
<li class="link">
<a href="ch-diagonalization.html" data-scroll="ch-diagonalization" class="internal"><span class="codenumber">4</span> <span class="title">Diagonalization</span></a><ul>
<li><a href="subsec-eigen-basics.html" data-scroll="subsec-eigen-basics" class="active">Eigenvalues and Eigenvectors</a></li>
<li><a href="subsec-ortho-diag.html" data-scroll="subsec-ortho-diag" class="internal">Diagonalization of symmetric matrices</a></li>
<li><a href="sec-quadratic.html" data-scroll="sec-quadratic" class="internal">Quadratic forms</a></li>
<li><a href="sec-complex.html" data-scroll="sec-complex" class="internal">Diagonalization of complex matrices</a></li>
<li><a href="section-matrix-factor.html" data-scroll="section-matrix-factor" class="internal">Matrix Factorizations and Eigenvalues</a></li>
<li><a href="worksheet-svd.html" data-scroll="worksheet-svd" class="internal">Worksheet: Singular Value Decomposition</a></li>
</ul>
</li>
<li class="link">
<a href="ch-change-basis.html" data-scroll="ch-change-basis" class="internal"><span class="codenumber">5</span> <span class="title">Change of Basis</span></a><ul>
<li><a href="sec-matrix-of-transformation.html" data-scroll="sec-matrix-of-transformation" class="internal">The matrix of a linear transformation</a></li>
<li><a href="sec-matrix-operator.html" data-scroll="sec-matrix-operator" class="internal">The matrix of a linear operator</a></li>
<li><a href="sec-direct-sum.html" data-scroll="sec-direct-sum" class="internal">Direct Sums and Invariant Subspaces</a></li>
<li><a href="worksheet-gen-eigen.html" data-scroll="worksheet-gen-eigen" class="internal">Worksheet: generalized eigenvectors</a></li>
<li><a href="sec-gen-eigen.html" data-scroll="sec-gen-eigen" class="internal">Generalized eigenspaces</a></li>
<li><a href="sec-jordan-form.html" data-scroll="sec-jordan-form" class="internal">Jordan Canonical Form</a></li>
</ul>
</li>
<li class="link backmatter"><a href="backmatter-1.html" data-scroll="backmatter-1" class="internal"><span class="title">Back Matter</span></a></li>
<li class="link">
<a href="ch-computation.html" data-scroll="ch-computation" class="internal"><span class="codenumber">A</span> <span class="title">Computational Tools</span></a><ul>
<li><a href="section-jupyter.html" data-scroll="section-jupyter" class="internal">Jupyter</a></li>
<li><a href="sec-python-basics.html" data-scroll="sec-python-basics" class="internal">Python basics</a></li>
<li><a href="sec-sympy.html" data-scroll="sec-sympy" class="internal">SymPy for linear algebra</a></li>
</ul>
</li>
<li class="link"><a href="solutions-1.html" data-scroll="solutions-1" class="internal"><span class="codenumber">B</span> <span class="title">Solutions to Selected Exercises</span></a></li>
</ul></nav><div class="extras"><nav><a class="pretext-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content"><section class="section" id="subsec-eigen-basics"><h2 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber">4.1</span> <span class="title">Eigenvalues and Eigenvectors</span>
</h2>
<article class="definition definition-like" id="def-eigenvalue"><h3 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">4.1.1</span><span class="period">.</span>
</h3>
<p id="p-962">Let <span class="process-math">\(A\)</span> be an <span class="process-math">\(n\times n\)</span> matrix. A number <span class="process-math">\(\lambda\)</span> is called an <dfn class="terminology">eigenvalue</dfn> of <span class="process-math">\(A\)</span> if there exists a nonzero vector <span class="process-math">\(\xx\)</span> such that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
A\xx = \lambda\xx\text{.}
\end{equation*}
</div>
<p class="continuation">Any such vector <span class="process-math">\(\xx\)</span> is called an <dfn class="terminology">eigenvector</dfn> associated to the eigenvalue <span class="process-math">\(\lambda\text{.}\)</span></p></article><p id="p-963">Note that eigenvalues and eigenvectors can just as easily be defined for a general linear operator <span class="process-math">\(T:V\to V\text{.}\)</span> In this context, and eigenvector <span class="process-math">\(\xx\)</span> is sometimes referred to as a <em class="emphasis">characteristic vector</em> (or characteristic direction) for <span class="process-math">\(T\text{,}\)</span> since the property <span class="process-math">\(T(\xx)=\lambda \xx\)</span> simply states that the transformed vector <span class="process-math">\(T(\xx)\)</span> is parallel to the original vector <span class="process-math">\(\xx\text{.}\)</span> Some linear algebra textbooks that focus more on general linear transformations frame this topic in the context of <em class="emphasis">invariant subspaces</em> for a linear operator.</p>
<p id="p-964">A subspace <span class="process-math">\(U\subseteq V\)</span> is <em class="emphasis">invariant</em> with respect to <span class="process-math">\(T\)</span> if <span class="process-math">\(T(\uu)\in U\)</span> for all <span class="process-math">\(\uu\in U\text{.}\)</span> Note that if <span class="process-math">\(\xx\)</span> is an eigenvector of <span class="process-math">\(T\text{,}\)</span> then <span class="process-math">\(\spn\{\xx\}\)</span> is an invariant subspace. To see this, note that if <span class="process-math">\(T(\xx)=\lambda \xx\)</span> and <span class="process-math">\(\yy=k\xx\text{,}\)</span> then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
T(\yy)=T(k\xx)=kT(\xx)=k(\lambda \xx)=\lambda(k\xx)=\lambda\yy\text{.}
\end{equation*}
</div>
<p id="p-965">Note that if <span class="process-math">\(\xx\)</span> is an eigenvector of the matrix <span class="process-math">\(A\text{,}\)</span> then we have</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq-eigen-null">
\begin{equation}
(A-\lambda I_n)\xx=\zer\text{,}\tag{4.1.1}
\end{equation}
</div>
<p class="continuation">where <span class="process-math">\(I_n\)</span> denotes the <span class="process-math">\(n\times n\)</span> identity matrix. Thus, if <span class="process-math">\(\lambda\)</span> is an eigenvalue of <span class="process-math">\(A\text{,}\)</span> any corresponding eigenvector is an element of <span class="process-math">\(\nll(A-\lambda I_n)\text{.}\)</span></p>
<article class="definition definition-like" id="def-eigenspace"><h3 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">4.1.2</span><span class="period">.</span>
</h3>
<p id="p-966">For any real number <span class="process-math">\(\lambda\)</span> and matrix <span class="process-math">\(A\text{,}\)</span> we define the <dfn class="terminology">eigenspace</dfn> <span class="process-math">\(E_\lambda(A)\)</span> by</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
E_\lambda(A) = \nll (A-\lambda I_n)\text{.}
\end{equation*}
</div></article><p id="p-967">Note that <span class="process-math">\(E_\lambda(A)\)</span> can be defined for any real number <span class="process-math">\(\lambda\text{,}\)</span> whether or not <span class="process-math">\(\lambda\)</span> is an eigenvalue. However, the eigenvalues of <span class="process-math">\(A\)</span> are distinguished by the property that there is a <em class="emphasis">nonzero</em> solution to <a href="" class="xref" data-knowl="./knowl/eq-eigen-null.html" title="Equation 4.1.1">(4.1.1)</a>. Furthermore, we know that <a href="" class="xref" data-knowl="./knowl/eq-eigen-null.html" title="Equation 4.1.1">(4.1.1)</a> can only have nontrivial solutions if the matrix <span class="process-math">\(A-\lambda I_n\)</span> is not invertible. We also know that <span class="process-math">\(A-\lambda I_n\)</span> is non-invertible if and only if <span class="process-math">\(\det (A-\lambda I_n) = 0\text{.}\)</span> This gives us the following theorem.</p>
<article class="theorem theorem-like" id="thm-eigenspace-nonzero"><h3 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">4.1.3</span><span class="period">.</span>
</h3>
<p id="p-968">The following are equivalent for any <span class="process-math">\(n\times n\)</span> matrix <span class="process-math">\(A\)</span> and real number <span class="process-math">\(\lambda\text{:}\)</span></p>
<ol class="decimal">
<li id="li-137"><p id="p-969"><span class="process-math">\(\lambda\)</span> is an eigenvalue of <span class="process-math">\(A\text{.}\)</span></p></li>
<li id="li-138"><p id="p-derived-li-138"><span class="process-math">\(\displaystyle E_\lambda(A)\neq \{\zer\}\)</span></p></li>
<li id="li-139"><p id="p-derived-li-139"><span class="process-math">\(\displaystyle \det(A-\lambda I_n) = 0\)</span></p></li>
</ol></article><p id="p-970">The polynomial <span class="process-math">\(p_A(x)=\det(xI_n -A)\)</span> is called the <dfn class="terminology">characteristic polynomial</dfn> of <span class="process-math">\(A\text{.}\)</span> (Note that <span class="process-math">\(\det(x I_n-A) = (-1)^n\det(A-x I_n)\text{.}\)</span> We choose this order so that the coefficient of <span class="process-math">\(x^n\)</span> is always 1.) The equation</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="eq-characteristic">
\begin{equation}
\det(xI_n - A) = 0\tag{4.1.2}
\end{equation}
</div>
<p class="continuation">is called the <dfn class="terminology">characteristic equation</dfn> of <span class="process-math">\(A\text{.}\)</span> The solutions to this equation are precisely the eigenvalues of <span class="process-math">\(A\text{.}\)</span></p>
<p id="p-971">Recall that a matrix <span class="process-math">\(B\)</span> is said to be <dfn class="terminology">similar</dfn> to a matrix <span class="process-math">\(A\)</span> if there exists an invertible matrix <span class="process-math">\(P\)</span> such that <span class="process-math">\(B = P^{-1}AP\text{.}\)</span> Much of what follows concerns the question of whether or not a given <span class="process-math">\(n\times n\)</span> matrix <span class="process-math">\(A\)</span> is <dfn class="terminology">diagonalizable</dfn>.</p>
<article class="definition definition-like" id="def-diagonalizable"><h3 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">4.1.4</span><span class="period">.</span>
</h3>
<p id="p-972">An <span class="process-math">\(n\times n\)</span> matrix <span class="process-math">\(A\)</span> is said to be <dfn class="terminology">diagonalizable</dfn> if <span class="process-math">\(A\)</span> is similar to a diagonal matrix.</p></article><p id="p-973">The following results will frequently be useful.</p>
<article class="theorem theorem-like" id="thm-similar-properties"><h3 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">4.1.5</span><span class="period">.</span>
</h3>
<p id="p-974">The relation <span class="process-math">\(A\sim B\)</span> if and only if <span class="process-math">\(A\)</span> is similar to <span class="process-math">\(B\)</span> is an equivalence relation. Moreover, if <span class="process-math">\(A\sim B\text{,}\)</span> then:</p>
<ul class="disc">
<li id="li-140"><p id="p-derived-li-140"><span class="process-math">\(\displaystyle \det A = \det B\)</span></p></li>
<li id="li-141"><p id="p-derived-li-141"><span class="process-math">\(\displaystyle \tr A = \tr B\)</span></p></li>
<li id="li-142"><p id="p-derived-li-142"><span class="process-math">\(\displaystyle c_A(x) = c_B(x)\)</span></p></li>
</ul>
<p class="continuation">In other words, <span class="process-math">\(A\)</span> and <span class="process-math">\(B\)</span> have the same determinant, trace, and characteristic polynomial (and thus, the same eigenvalues).</p></article><article class="hiddenproof" id="proof-46"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-46"><h3 class="heading"><span class="type">Proof<span class="period">.</span></span></h3></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-46"><article class="hiddenproof"><p id="p-975">The first two follow directly from properties of the determinant and trace. For the last, note that if <span class="process-math">\(B = P^{-1}AP\text{,}\)</span> then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P^{-1}(xI_n-A)P = P^{-1}(xI_n)P-P^{-1}AP = xI_n B\text{,}
\end{equation*}
</div>
<p class="continuation">so <span class="process-math">\(xI_n-B\sim xI_n-A\text{,}\)</span> and therefore <span class="process-math">\(\det(xI_n-B)=\det(xI_n-A)\text{.}\)</span></p></article></div>
<article class="example example-like" id="example-13"><h3 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.1.6</span><span class="period">.</span>
</h3>
<p id="p-976">Determine the eigenvalues and eigenvectors of <span class="process-math">\(A = \bbm 0\amp 1\amp 1\\1\amp 0\amp 1\\1\amp 1\amp 0\ebm\text{.}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-58" id="solution-58"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-58"><div class="solution solution-like">
<p id="p-977">We begin with the characteristic polynomial. We have</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-62">
\begin{align*}
\det(xI_n - A) \amp =\det\bbm x \amp -1\amp -1\\-1\amp x \amp -1\\-1\amp -1\amp x\ebm\\
\amp = x \begin{vmatrix}x \amp -1\\-1\amp x\end{vmatrix}
+1\begin{vmatrix}-1\amp -1\\-1\amp x\end{vmatrix}
-1\begin{vmatrix}-1\amp x\\-1\amp -1\end{vmatrix}\\
\amp = x(x^2-1)+(-x-1)-(1+x)\\
\amp x(x-1)(x+1)-2(x+1)\\
\amp (x+1)[x^2-x-2]\\
\amp (x+1)^2(x-2)\text{.}
\end{align*}
</div>
<p id="p-978">The roots of the characteristic polynomial are our eigenvalues, so we have <span class="process-math">\(\lambda_1=-1\)</span> and <span class="process-math">\(\lambda_2=2\text{.}\)</span> Note that the first eigenvalue comes from a repeated root. This is typically where things get interesting. If an eigenvalue does not come from a repeated root, then there will only be one (independent) eigenvector that corresponds to it. (That is, <span class="process-math">\(\dim E_\lambda(A)=1\text{.}\)</span>) If an eigenvalue is repeated, it could have more than one eigenvector, but this is not guaranteed.</p>
<p id="p-979">We find that <span class="process-math">\(A-(-1)I_n = \bbm 1\amp 1\amp 1\\1\amp 1\amp 1\\1\amp 1\amp 1\ebm\text{,}\)</span> which has reduced row-echelon form <span class="process-math">\(\bbm 1\amp 1\amp 1\\0\amp 0\amp 0\\0\amp 0\amp 0\ebm\text{.}\)</span> Solving for the nullspace, we find that there are two independent eigenvectors:</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\xx_{1,1}=\bbm 1\\-1\\0\ebm, \quad \text{ and } \quad \xx_{1,2}=\bbm 1\\0\\-1\ebm\text{,}
\end{equation*}
</div>
<p class="continuation">so</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
E_{-1}(A) = \spn\left\{\bbm 1\\-1\\0\ebm, \bbm 1\\0\\-1\ebm\right\}\text{.}
\end{equation*}
</div>
<p id="p-980">For the second eigenvector, we have <span class="process-math">\(A-2I = \bbm -2\amp 1\amp 1\\1\amp -2\amp 1\\1\amp 1\amp -2\ebm\text{,}\)</span> which has reduced row-echelon form <span class="process-math">\(\bbm 1\amp 0\amp -1\\0\amp 1\amp -1\\0\amp 0\amp 0\ebm\text{.}\)</span> An eigenvector in this case is given by</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\xx_2 = \bbm 1\\1\\1\ebm\text{.}
\end{equation*}
</div>
</div></div>
</div></article><p id="p-981">In general, if the characteristic polynomial can be factored as</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
p_A(x)=(x-\lambda)^mq(x)\text{,}
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(q(x)\)</span> is not divisible by <span class="process-math">\(x-\lambda\text{,}\)</span> then we say that <span class="process-math">\(\lambda\)</span> is an eigenvalue of <dfn class="terminology">multiplicity</dfn> <span class="process-math">\(m\text{.}\)</span> A main result is the following.</p>
<article class="theorem theorem-like" id="thm-multiplicity"><h3 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">4.1.7</span><span class="period">.</span>
</h3>
<p id="p-982">Let <span class="process-math">\(\lambda\)</span> be an eigenvalue of <span class="process-math">\(A\)</span> of multiplicity <span class="process-math">\(m\text{.}\)</span> Then <span class="process-math">\(\dim E_\lambda(A)\leq m\text{.}\)</span></p></article><p id="p-983">Some textbooks refer to the multiplicity <span class="process-math">\(m\)</span> of an eigenvalue as the <em class="emphasis">algebraic multiplicity</em> of <span class="process-math">\(\lambda\text{,}\)</span> and the number <span class="process-math">\(\dim E_\lambda(A)\)</span> as the <em class="emphasis">geometric multiplicity</em> of <span class="process-math">\(\lambda\text{.}\)</span></p>
<p id="p-984">To prove <a href="" class="xref" data-knowl="./knowl/thm-multiplicity.html" title="Theorem 4.1.7">TheoremÂ 4.1.7</a> we need the following lemma, from Section 5.5 of Nicholson's textbook.</p>
<article class="lemma theorem-like" id="lem-block-eigen"><h3 class="heading">
<span class="type">Lemma</span><span class="space"> </span><span class="codenumber">4.1.8</span><span class="period">.</span>
</h3>
<p id="p-985">Let <span class="process-math">\(\{\xx_1,\ldots, \xx_k\}\)</span> be a set of linearly independent eigenvectors of a matrix <span class="process-math">\(A\text{,}\)</span> with corresponding eigenvalues <span class="process-math">\(\lambda_1,\ldots, \lambda_k\)</span> (not necessarily distinct). Extend this set to a basis <span class="process-math">\(\{\xx_1,\ldots, \xx_k,\xx_{k+1},\ldots, \xx_n\}\text{,}\)</span> and let <span class="process-math">\(P=\bbm \xx_1\amp \cdots \amp \xx_n\ebm\)</span> be the matrix whose columns are the basis vectors. (Note that <span class="process-math">\(P\)</span> is necessarily invertible.) Then</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
P^{-1}AP = \bbm \diag(\lambda_1,\ldots, \lambda_k) \amp B\\0\amp A_1\ebm\text{,}
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(B\)</span> has size <span class="process-math">\(k\times (n-k)\text{,}\)</span> and <span class="process-math">\(A_1\)</span> has size <span class="process-math">\((n-k)\times (n-k)\text{.}\)</span></p></article><article class="hiddenproof" id="proof-47"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-47"><h3 class="heading"><span class="type">Proof<span class="period">.</span></span></h3></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-47"><article class="hiddenproof"><p id="p-986">We have</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-63">
\begin{align*}
P^{-1}AP \amp = P^{-1}A\bbm \xx_1\amp \cdots \amp \xx_n\ebm\\
\amp =\bbm (P^{-1}A)\xx_1\amp \cdots \amp (P^{-1}A)\xx_n\ebm\text{.}
\end{align*}
</div>
<p class="continuation">For <span class="process-math">\(1\leq i\leq k\text{,}\)</span> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
(P^{-1}A)(\xx_i) = P^{-1}(A\xx_i) = P^{-1}(\lambda_i\xx_i)=\lambda_i(P^{-1}\xx_i)\text{.}
\end{equation*}
</div>
<p class="continuation">But <span class="process-math">\(P^{-1}\xx_i\)</span> is the <span class="process-math">\(i\)</span>th column of <span class="process-math">\(P^{-1}P = I_n\text{,}\)</span> which proves the result.</p></article></div>
<p id="p-987">We can use <a href="" class="xref" data-knowl="./knowl/lem-block-eigen.html" title="Lemma 4.1.8">LemmaÂ 4.1.8</a> to prove that <span class="process-math">\(\dim E_\lambda(A)\leq m\)</span> as follows. Suppose <span class="process-math">\(\{\xx_1,\ldots, \xx_k\}\)</span> is a basis for <span class="process-math">\(E_\lambda(A)\text{.}\)</span> Then this is a linearly independent set of eigenvectors, so our lemma guarantees the existence of a matrix <span class="process-math">\(P\)</span> such that</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/lem-block-eigen.html">
\begin{equation*}
P^{-1}AP = \bbm \lambda I_k \amp B\\0\amp A_1\ebm\text{.}
\end{equation*}
</div>
<p class="continuation">Let <span class="process-math">\(\tilde{A}=P^{-1}AP\text{.}\)</span> On the one hand, since <span class="process-math">\(\tilde{A}\sim A\text{,}\)</span> we have <span class="process-math">\(c_A(x)=c_{\tilde{A}}(x)\text{.}\)</span> On the other hand,</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/lem-block-eigen.html">
\begin{equation*}
\det(xI_n-\tilde{A}) = \det\bbm (x-\lambda)I_k \amp -B\\0 \amp xI_{n-k}-A_1\ebm = (x-\lambda)^k\det(xI_{n-k}-A_1)\text{.}
\end{equation*}
</div>
<p class="continuation">This shows that <span class="process-math">\(c_A(x)\)</span> is divisible by <span class="process-math">\((x-\lambda)^k\text{.}\)</span> Since <span class="process-math">\(m\)</span> is the largest integer such that <span class="process-math">\(c_A(x)\)</span> is divisible by <span class="process-math">\((x-\lambda)^m\text{,}\)</span> we must have <span class="process-math">\(\dim E_\lambda(A)=k\leq m\text{.}\)</span></p>
<p id="p-988"><a href="" class="xref" data-knowl="./knowl/thm-multiplicity.html" title="Theorem 4.1.7">TheoremÂ 4.1.7</a> provides an initial criterion for diagonalization: if the dimension of each eigenspace <span class="process-math">\(E_\lambda(A)\)</span> is equal to the multiplicity of <span class="process-math">\(\lambda\text{,}\)</span> then <span class="process-math">\(A\)</span> is diagonalizable. The truth of this statement relies on one additional fact: any set of eigenvectors corresponding to <em class="emphasis">distinct</em> eigenvalues is linearly independent. The proof of this fact is a relatively straightforward proof by induction. It can be found in Section 5.5 of Nicholson for those who are interested. However, our focus for the remainder of the section will be on diagonalization of <em class="emphasis">symmetric</em> matrices, and soon we will see that for such matrices, eigenvectors corresponding to different eigenvalues are, in fact, <em class="emphasis">orthogonal</em>.</p>
<div id="scprogresscontainer">You have attempted <span id="scprogresstotal"></span> of <span id="scprogressposs"></span> activities on this page.<div id="subchapterprogress" aria-label="Page progress"></div>
</div></section></div></main>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-core.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/autoloader/prism-autoloader.min.js"></script>
</body>
</html>
