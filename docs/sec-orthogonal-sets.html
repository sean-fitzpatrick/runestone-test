<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*       on 2022-06-24T11:24:08-06:00       *-->
<!--*   A recent stable commit (2020-08-09):   *-->
<!--* 98f21740783f166a773df4dc83cab5293ab63a4a *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Orthogonal sets of vectors</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="Linear Algebra">
<meta property="book:author" content="Sean Fitzpatrick">
<script src="https://sagecell.sagemath.org/static/embedded_sagecell.js"></script><script>window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore|ignore-math",
    processHtmlClass: "process-math",
    renderActions: {
        findScript: [10, function (doc) {
            document.querySelectorAll('script[type^="math/tex"]').forEach(function(node) {
                var display = !!node.type.match(/; *mode=display/);
                var math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                var text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = {node: text, delim: '', n: 0};
                math.end = {node: text, delim: '', n: 0};
                doc.math.push(math);
            });
        }, '']
    },
  },
  chtml: {
    scale: 0.88,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><script>// Make *any* pre with class 'sagecell-sage' an executable Sage cell
// Their results will be linked, only within language type
sagecell.makeSagecell({inputLocation: 'pre.sagecell-sage',
                       linked: true,
                       languages: ['sage'],
                       evalButtonText: 'Evaluate (Sage)'});
</script><link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/themes/prism.css" rel="stylesheet">
<script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.13/pretext.js"></script><script>miniversion=0.674</script><script src="https://pretextbook.org/js/0.13/pretext_add_on.js?x=1"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<script src="https://cdn.geogebra.org/apps/deployggb.js"></script><link href="https://pretextbook.org/css/0.4/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/colors_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.4/setcolors.css" rel="stylesheet" type="text/css">
<!--** eBookCongig is necessary to configure interactive       **-->
<!--** Runestone components to run locally in reader's browser **-->
<!--** No external communication:                              **-->
<!--**     log level is 0, Runestone Services are disabled     **-->
<script type="text/javascript">
eBookConfig = {};
eBookConfig.useRunestoneServices = false;
eBookConfig.host = 'http://127.0.0.1:8000';
eBookConfig.course = 'PTX Course: Title Here';
eBookConfig.basecourse = 'PTX Base Course';
eBookConfig.isLoggedIn = false;
eBookConfig.email = '';
eBookConfig.isInstructor = false;
eBookConfig.logLevel = 0;
eBookConfig.username = '';
eBookConfig.readings = null;
eBookConfig.activities = null;
eBookConfig.downloadsEnabled = false;
eBookConfig.allow_pairs = false;
eBookConfig.enableScratchAC = false;
eBookConfig.build_info = "";
eBookConfig.python3 = null;
eBookConfig.acDefaultLanguage = 'python';
eBookConfig.runestone_version = '5.0.1';
eBookConfig.jobehost = '';
eBookConfig.proxyuri_runs = '';
eBookConfig.proxyuri_files = '';
eBookConfig.enable_chatcodes =  false;
</script>
<!--*** Runestone Services ***-->
<script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/runtime.b0f8547c48f16a9f.bundle.js"></script><script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/637.d54be67956c5c660.bundle.js"></script><script type="text/javascript" src="https://runestone.academy/cdn/runestone/6.2.1/runestone.0e9550fe42760516.bundle.js"></script><link rel="stylesheet" type="text/css" href="https://runestone.academy/cdn/runestone/6.2.1/637.fafafbd97df8a0d1.css">
<link rel="stylesheet" type="text/css" href="https://runestone.academy/cdn/runestone/6.2.1/runestone.e4d5592da655219f.css">
</head>
<body class="pretext-book ignore-math has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\newcommand{\spn}{\operatorname{span}}
\newcommand{\bbm}{\begin{bmatrix}}
\newcommand{\ebm}{\end{bmatrix}}
\newcommand{\R}{\mathbb{R}}
\ifdefined\C
\renewcommand\C{\mathbb{C}}
\else
\newcommand\C{\mathbb{C}}
\fi
\newcommand{\im}{\operatorname{im}}
\newcommand{\nll}{\operatorname{null}}
\newcommand{\csp}{\operatorname{col}}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\diag}{\operatorname{diag}}
\newcommand{\tr}{\operatorname{tr}}
\newcommand{\dotp}{\!\boldsymbol{\cdot}\!}
\newcommand{\len}[1]{\lVert #1\rVert}
\newcommand{\abs}[1]{\lvert #1\rvert}
\newcommand{\proj}[2]{\operatorname{proj}_{#1}{#2}}
\newcommand{\bz}{\overline{z}}
\newcommand{\zz}{\mathbf{z}}
\newcommand{\uu}{\mathbf{u}}
\newcommand{\vv}{\mathbf{v}}
\newcommand{\ww}{\mathbf{w}}
\newcommand{\xx}{\mathbf{x}}
\newcommand{\yy}{\mathbf{y}}
\newcommand{\zer}{\mathbf{0}}
\newcommand{\vecq}{\mathbf{q}}
\newcommand{\vecp}{\mathbf{p}}
\newcommand{\vece}{\mathbf{e}}
\newcommand{\basis}[2]{\{\mathbf{#1}_1,\mathbf{#1}_2,\ldots,\mathbf{#1}_{#2}\}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="linear-algebra.html"><span class="title">Linear Algebra:</span> <span class="subtitle">A second course, featuring proofs and Python</span></a></h1>
<p class="byline">Sean Fitzpatrick</p>
</div>
</div></div>
<nav id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3">
<button id="calculator-toggle" class="toolbar-item button toggle" title="Show calculator" aria-expanded="false" aria-controls="calculator-container">Calc</button><div id="calculator-container" class="calculator-container" style="display: none; z-index:100;"><div id="geogebra-calculator"></div></div>
<script>
var ggbApp = new GGBApplet({"appName": "graphing",
    "width": 330,
    "height": 600,
    "showToolBar": true,
    "showAlgebraInput": true,
    "perspective": "G/A",
    "algebraInputPosition": "bottom",
    "scaleContainerClass": "calculator-container",
    "allowUpscale": true,
    "autoHeight": true,
    "disableAutoScale": false},
true);
</script><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="ch-orthogonality.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="ch-orthogonality.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="sec-ortho-projection.html" title="Next">Next</a></span>
</div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="ch-orthogonality.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="ch-orthogonality.html" title="Up">Up</a><a class="next-button button toolbar-item" href="sec-ortho-projection.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link frontmatter">
<a href="frontmatter-1.html" data-scroll="frontmatter-1" class="internal"><span class="title">Front Matter</span></a><ul>
<li><a href="colophon-1.html" data-scroll="colophon-1" class="internal">Colophon</a></li>
<li><a href="preface-1.html" data-scroll="preface-1" class="internal">Preface</a></li>
</ul>
</li>
<li class="link">
<a href="ch-vector-space.html" data-scroll="ch-vector-space" class="internal"><span class="codenumber">1</span> <span class="title">Vector spaces</span></a><ul>
<li><a href="sec-vec-sp.html" data-scroll="sec-vec-sp" class="internal">Definition and examples</a></li>
<li><a href="sec-vsp-properties.html" data-scroll="sec-vsp-properties" class="internal">Properties</a></li>
<li><a href="sec-subspace.html" data-scroll="sec-subspace" class="internal">Subspaces</a></li>
<li><a href="sec-span.html" data-scroll="sec-span" class="internal">Span</a></li>
<li><a href="worksheet-span.html" data-scroll="worksheet-span" class="internal">Worksheet: understanding span</a></li>
<li><a href="sec-independence.html" data-scroll="sec-independence" class="internal">Linear Independence</a></li>
<li><a href="sec-dimension.html" data-scroll="sec-dimension" class="internal">Basis and dimension</a></li>
<li><a href="sec-subspace-combine.html" data-scroll="sec-subspace-combine" class="internal">New subspaces from old</a></li>
</ul>
</li>
<li class="link">
<a href="ch-linear-trans.html" data-scroll="ch-linear-trans" class="internal"><span class="codenumber">2</span> <span class="title">Linear Transformations</span></a><ul>
<li><a href="sec-lin-tran-intro.html" data-scroll="sec-lin-tran-intro" class="internal">Definition and examples</a></li>
<li><a href="sec-kernel-image.html" data-scroll="sec-kernel-image" class="internal">Kernel and Image</a></li>
<li><a href="sec-isomorphism.html" data-scroll="sec-isomorphism" class="internal">Isomorphisms, composition, and inverses</a></li>
<li><a href="worksheet-transformations.html" data-scroll="worksheet-transformations" class="internal">Worksheet: matrix transformations</a></li>
<li><a href="worksheet-recurrence.html" data-scroll="worksheet-recurrence" class="internal">Worksheet: linear recurrences</a></li>
</ul>
</li>
<li class="link">
<a href="ch-orthogonality.html" data-scroll="ch-orthogonality" class="internal"><span class="codenumber">3</span> <span class="title">Orthogonality and Applications</span></a><ul>
<li><a href="sec-orthogonal-sets.html" data-scroll="sec-orthogonal-sets" class="active">Orthogonal sets of vectors</a></li>
<li><a href="sec-ortho-projection.html" data-scroll="sec-ortho-projection" class="internal">Orthogonal Projection</a></li>
<li><a href="worksheet-dual-basis.html" data-scroll="worksheet-dual-basis" class="internal">Worksheet: dual basis.</a></li>
</ul>
</li>
<li class="link">
<a href="ch-diagonalization.html" data-scroll="ch-diagonalization" class="internal"><span class="codenumber">4</span> <span class="title">Diagonalization</span></a><ul>
<li><a href="subsec-eigen-basics.html" data-scroll="subsec-eigen-basics" class="internal">Eigenvalues and Eigenvectors</a></li>
<li><a href="subsec-ortho-diag.html" data-scroll="subsec-ortho-diag" class="internal">Diagonalization of symmetric matrices</a></li>
<li><a href="sec-quadratic.html" data-scroll="sec-quadratic" class="internal">Quadratic forms</a></li>
<li><a href="sec-complex.html" data-scroll="sec-complex" class="internal">Diagonalization of complex matrices</a></li>
<li><a href="section-matrix-factor.html" data-scroll="section-matrix-factor" class="internal">Matrix Factorizations and Eigenvalues</a></li>
<li><a href="worksheet-svd.html" data-scroll="worksheet-svd" class="internal">Worksheet: Singular Value Decomposition</a></li>
</ul>
</li>
<li class="link">
<a href="ch-change-basis.html" data-scroll="ch-change-basis" class="internal"><span class="codenumber">5</span> <span class="title">Change of Basis</span></a><ul>
<li><a href="sec-matrix-of-transformation.html" data-scroll="sec-matrix-of-transformation" class="internal">The matrix of a linear transformation</a></li>
<li><a href="sec-matrix-operator.html" data-scroll="sec-matrix-operator" class="internal">The matrix of a linear operator</a></li>
<li><a href="sec-direct-sum.html" data-scroll="sec-direct-sum" class="internal">Direct Sums and Invariant Subspaces</a></li>
<li><a href="worksheet-gen-eigen.html" data-scroll="worksheet-gen-eigen" class="internal">Worksheet: generalized eigenvectors</a></li>
<li><a href="sec-gen-eigen.html" data-scroll="sec-gen-eigen" class="internal">Generalized eigenspaces</a></li>
<li><a href="sec-jordan-form.html" data-scroll="sec-jordan-form" class="internal">Jordan Canonical Form</a></li>
</ul>
</li>
<li class="link backmatter"><a href="backmatter-1.html" data-scroll="backmatter-1" class="internal"><span class="title">Back Matter</span></a></li>
<li class="link">
<a href="ch-computation.html" data-scroll="ch-computation" class="internal"><span class="codenumber">A</span> <span class="title">Computational Tools</span></a><ul>
<li><a href="section-jupyter.html" data-scroll="section-jupyter" class="internal">Jupyter</a></li>
<li><a href="sec-python-basics.html" data-scroll="sec-python-basics" class="internal">Python basics</a></li>
<li><a href="sec-sympy.html" data-scroll="sec-sympy" class="internal">SymPy for linear algebra</a></li>
</ul>
</li>
<li class="link"><a href="solutions-1.html" data-scroll="solutions-1" class="internal"><span class="codenumber">B</span> <span class="title">Solutions to Selected Exercises</span></a></li>
</ul></nav><div class="extras"><nav><a class="pretext-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content"><section class="section" id="sec-orthogonal-sets"><h2 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber">3.1</span> <span class="title">Orthogonal sets of vectors</span>
</h2>
<section class="introduction" id="introduction-17"><p id="p-788">You may recall from elementary linear algebra, or a calculus class, that vectors in <span class="process-math">\(\R^2\)</span> or <span class="process-math">\(\R^3\)</span> are considered to be quantities with both <em class="emphasis">magnitude</em> and <em class="emphasis">direction</em>. Interestingly enough, neither of these properties is inherent to a general vector space. The vector space axioms specify only algebra; they say nothing about geometry. (What, for example, should be the “angle” between two polynomials?)</p>
<p id="p-789">Because vector algebra is often introduced as a consequence of geometry (like the “tip-to-tail” rule), you may not have thought all that carefully about what, exactly, is responsible for making the connection between algebra and geometry. It turns out that the missing link is the humble dot product.</p>
<p id="p-790">You probably encountered the following result, perhaps as a consequence of the law of cosines: for any two vectors <span class="process-math">\(\uu,\vv\in\R^2\text{,}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\uu\dotp\vv = \len{\uu}\,\len{\vv}\cos\theta\text{,}
\end{equation*}
</div>
<p class="continuation">where <span class="process-math">\(\theta\)</span> is the angle between <span class="process-math">\(\uu\)</span> and <span class="process-math">\(\vv\text{.}\)</span> Here we see both magnitude and direction (encoded by the angle) defined in terms of the dot product.</p>
<p id="p-791">While it is possible to generalize the idea of the dot product to something called an <em class="emphasis">inner product</em>, we will first focus on the basic dot product in <span class="process-math">\(\R^n\text{.}\)</span> Once we have a good understanding of things in that setting, we can move on to consider the abstract counterpart.</p></section><section class="subsection" id="subsec-dot-basics"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">3.1.1</span> <span class="title">Basic definitions and properties</span>
</h3>
<p id="p-792">For most of this chapter (primarily for typographical reasons) we will denote elements of <span class="process-math">\(\R^n\)</span> as ordered <span class="process-math">\(n\)</span>-tuples <span class="process-math">\((x_1,\ldots, x_n)\)</span> rather than as column vectors.</p>
<article class="definition definition-like" id="def-dot-prod-norm"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">3.1.1</span><span class="period">.</span>
</h4>
<p id="p-793">Let <span class="process-math">\(\xx=(x_1,x_2,\ldots, x_n)\)</span> and <span class="process-math">\(\yy=(y_1,y_2,\ldots, y_n)\)</span> be vectors in <span class="process-math">\(\R^n\text{.}\)</span> The <dfn class="terminology">dot product</dfn> of <span class="process-math">\(\xx\)</span> and <span class="process-math">\(\yy\text{,}\)</span> denoted by <span class="process-math">\(\xx\dotp\yy\)</span> is the scalar defined by</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\xx\dotp \yy = x_1y_1+x_2y_2+\cdots + x_ny_n\text{.}
\end{equation*}
</div>
<p class="continuation">The <dfn class="terminology">norm</dfn> of a vector <span class="process-math">\(\xx\)</span> is denoted <span class="process-math">\(\len{\xx}\)</span> and defined by</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\len{\xx} = \sqrt{x_1^2+x_2^2+\cdots + x_n^2}\text{.}
\end{equation*}
</div></article><p id="p-794">Note that both the dot product and the norm produce <em class="emphasis">scalars</em>. Through the Pythagorean Theorem, we recognize the norm as the length of <span class="process-math">\(\xx\text{.}\)</span> The dot product can still be thought of as measuring the angle between vectors, although the simple geometric proof used in two dimensions is not that easily translated to <span class="process-math">\(n\)</span> dimensions. At the very least, the dot product lets us extend the notion of right angles to higher dimensions.</p>
<article class="definition definition-like" id="def-orthogonal"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">3.1.2</span><span class="period">.</span>
</h4>
<p id="p-795">We say that two vectors <span class="process-math">\(\xx,\yy\in\R^n\)</span> are <dfn class="terminology">orthogonal</dfn> if <span class="process-math">\(\xx\dotp\yy = 0\text{.}\)</span></p></article><p id="p-796">It should be no surprise that all the familiar properties of the dot product work just as well in any dimension. The folowing properties can be confirmed by direct computation, so the proof is left as an exercise.</p>
<article class="theorem theorem-like" id="thm-dot-props"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">3.1.3</span><span class="period">.</span>
</h4>
<p id="p-797">For any vectors <span class="process-math">\(\xx,\yy,\zz\in\R^n\text{,}\)</span></p>
<ol class="decimal">
<li id="li-111"><p id="p-derived-li-111"><span class="process-math">\(\displaystyle \xx\dotp\yy = \yy\dotp\xx\)</span></p></li>
<li id="li-112"><p id="p-derived-li-112"><span class="process-math">\(\displaystyle \xx\dotp(\yy+\zz)=\xx\dotp\yy+\xx\dotp\zz\)</span></p></li>
<li id="li-113"><p id="p-798">For any scalar <span class="process-math">\(c\text{,}\)</span> <span class="process-math">\(\xx\dotp(c\yy) = (c\xx)\dotp\yy=c(\xx\dotp\yy)\)</span></p></li>
<li id="li-114"><p id="p-799"><span class="process-math">\(\xx\dotp\xx\geq 0\text{,}\)</span> and <span class="process-math">\(\xx\dotp\xx=0\)</span> if and only if <span class="process-math">\(\xx=\zer\)</span></p></li>
</ol></article><p id="p-800">The above properties, when properly abstracted, become the defining properties of a (real) inner product. (A complex inner product also involves complex conjugates.) For a general inner product, the requirement <span class="process-math">\(\xx\dotp\xx\geq 0\)</span> is referred to as being <em class="emphasis">positive-definite</em>, and the property that only the zero vector produces zero when dotted with itself is called <em class="emphasis">nondegenerate</em>. Note that we have the following connection between norm and dot product:</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\len{\xx}^2 = \xx\dotp \xx\text{.}
\end{equation*}
</div>
<p class="continuation">For a general inner product, this can be used as a <em class="emphasis">definition</em> of the norm associated to an inner product.</p>
<article class="exercise exercise-like" id="exercise-63"><h4 class="heading">
<span class="type">Exercise</span><span class="space"> </span><span class="codenumber">3.1.4</span><span class="period">.</span>
</h4>
<p id="p-801">Given that <span class="process-math">\(\len{\xx}=3, \len{\yy}=1\text{,}\)</span> and <span class="process-math">\(\xx\dotp\yy=-2\text{,}\)</span> compute <span class="process-math">\((4\xx-3\yy)\dotp (\xx+5\yy)\text{.}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-28" id="hint-28"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-28"><div class="hint solution-like"><p id="p-802">Use properties of the dot product to expand and simplify.</p></div></div>
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-44" id="solution-44"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-44"><div class="solution solution-like">
<p id="p-803">Note that the distributive property, together with symmetry, let us handle this dot product using what is essentially “<abbr class="initialism">FOIL</abbr>”:</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-41">
\begin{align*}
(4\xx-3\yy)\dotp (\xx+5\yy)\amp = (4\xx)\dotp \xx+(4\xx)\dotp(5\yy)+(-3\yy)\dotp \xx+(-3\yy)\dotp(5\yy)\\
\amp = 4(\xx\dotp\xx)+(4\cdot 5)(\xx\dotp \yy)-3(\yy\dotp \xx)+(-3\cdot 5)(\yy\dotp\yy)\\
\amp = 4\len{\xx}^2+20\xx\dotp\yy-3\xx\dotp\yy-15\len{\yy}^2\\
\amp = 4(9)+17(-2)-15(1) = -13\text{.}
\end{align*}
</div>
</div></div>
</div></article><article class="exercise exercise-like" id="ex-norm-sum-square"><h4 class="heading">
<span class="type">Exercise</span><span class="space"> </span><span class="codenumber">3.1.5</span><span class="period">.</span>
</h4>
<p id="p-804">Show that for any vectors <span class="process-math">\(\xx,\yy\in\R^n\text{,}\)</span> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\len{\xx+\yy}^2 = \len{\xx}^2+2\xx\dotp\yy+\len{\yy}^2\text{.}
\end{equation*}
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-29" id="hint-29"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-29"><div class="hint solution-like"><p id="p-805">Use properties of the dot product to expand and simplify.</p></div></div>
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-45" id="solution-45"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-45"><div class="solution solution-like">
<p id="p-806">This is simply an exercise in properties of the dot product. We have</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-42">
\begin{align*}
\len{\xx+\yy}^2 \amp = (\xx+\yy)\dotp (\xx+\yy) \\
\amp = \xx\dotp \xx+\xx\dotp\yy+\yy\dotp\xx+\yy\dotp\yy\\
\amp =\len{\xx}^2+2\xx\dotp\yy+\len{\yy}^2\text{.}
\end{align*}
</div>
</div></div>
</div></article><article class="exercise exercise-like" id="exercise-65"><h4 class="heading">
<span class="type">Exercise</span><span class="space"> </span><span class="codenumber">3.1.6</span><span class="period">.</span>
</h4>
<p id="p-807">Suppose <span class="process-math">\(\mathbb{R}^n=\spn\{\vv_1,\vv_2,\ldots, \vv_k\}\text{.}\)</span> Prove that <span class="process-math">\(\xx=\zer\)</span> if and only if <span class="process-math">\(\xx\dotp \vv_i=0\)</span> for each <span class="process-math">\(i=1,2,\ldots, k\text{.}\)</span></p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-30" id="hint-30"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-30"><div class="hint solution-like"><p id="p-808">Don't forget to prove both directions! Note that the hypothesis allows you to write <span class="process-math">\(\xx\)</span> as a linear combination of the <span class="process-math">\(\vv_i\text{.}\)</span></p></div></div>
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-46" id="solution-46"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-46"><div class="solution solution-like">
<p id="p-809">If <span class="process-math">\(\xx=\zer\text{,}\)</span> then the result follows immediately from the dot product formula in <a href="" class="xref" data-knowl="./knowl/def-dot-prod-norm.html" title="Definition 3.1.1">Definition 3.1.1</a>. Conversely, suppose <span class="process-math">\(\xx\dotp \vv_i=0\)</span> for each <span class="process-math">\(i\text{.}\)</span> Since the <span class="process-math">\(\vv_i\)</span> span <span class="process-math">\(\R^n\text{,}\)</span> there must exist scalars <span class="process-math">\(c_1,c_2,\ldots, c_k\)</span> such that <span class="process-math">\(\xx=c_1\vv_1+c_2\vv_2+\cdots+c_k\vv_k\text{.}\)</span> But then</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/def-dot-prod-norm.html" id="md-43">
\begin{align*}
\xx\dotp\xx \amp = \xx\dotp (c_1\vv_1+c_2\vv_2+\cdots+c_k\vv_k) \\
\amp = c_1(\xx\dotp \vv_1)+ c_2(\xx\dotp \vv_2)+\cdots +c_k(\xx\dotp \vv_k)\\
\amp = c_1(0)+c_2(0)+\cdots + c_k(0)=0\text{.}
\end{align*}
</div>
</div></div>
</div></article><p id="p-810">There are two important inequalities associated to the dot product and norm. We state them both in the following theorem, without proof.</p>
<article class="theorem theorem-like" id="thm-cauchy-triangle"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">3.1.7</span><span class="period">.</span>
</h4>
<p id="p-811">Let <span class="process-math">\(\xx,\yy\)</span> be any vectors in <span class="process-math">\(\R^n\text{.}\)</span> Then</p>
<ol class="decimal">
<li id="li-115"><p id="p-derived-li-115"><span class="process-math">\(\displaystyle \lvert \xx\dotp \yy\rvert \leq \len{\xx}\len{\yy}\)</span></p></li>
<li id="li-116"><p id="p-derived-li-116"><span class="process-math">\(\displaystyle \len{\xx+\yy}\leq \len{\xx}+\len{\yy}\)</span></p></li>
</ol></article><p id="p-812">The first of the above inequalities is called the <em class="emphasis">Cauchy-Schwarz inequality</em>, which be viewed as a manifestation of the formula</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\xx\dotp \yy = \len{\xx}\len{\yy}\cos\theta\text{,}
\end{equation*}
</div>
<p class="continuation">since after all, <span class="process-math">\(\lvert \cos\theta\rvert\leq 1\)</span> for any angle <span class="process-math">\(\theta\text{.}\)</span></p>
<p id="p-813">The usual proof involves some algebraic trickery; the interested reader is invited to search online for the Cauchy-Schwarz inequality, where they will find no shortage of websites offering proofs.</p>
<p id="p-814">The second result, called the  <em class="emphasis">triangle inequality</em>, follows immediately from the Cauchy-Scwarz inequality and <a href="" class="xref" data-knowl="./knowl/ex-norm-sum-square.html" title="Exercise 3.1.5">Exercise 3.1.5</a>:</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/ex-norm-sum-square.html">
\begin{equation*}
\len{\xx+\yy}^2 = \len{\xx}^2+2\xx\dotp\yy+\len{\yy^2}\leq \len{\xx}^2+2\len{\xx}\len{\yy}+\len{\yy}^2=(\len{\xx}+\len{\yy})^2\text{.}
\end{equation*}
</div>
<p id="p-815">The triangle inequality gets its name from the “tip-to-tail” picture for vector addition. Essentially, it tells us that the length of any side of a triangle must be less than the sum of the lengths of the other two sides. The importance of the triangle inequality is that it tells us that the norm can be used to define distance.</p>
<article class="definition definition-like" id="def-vector-distance"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">3.1.8</span><span class="period">.</span>
</h4>
<p id="p-816">For any vectors <span class="process-math">\(\xx,\yy\in \R^n\text{,}\)</span> the <dfn class="terminology">distance</dfn> from <span class="process-math">\(\xx\)</span> to <span class="process-math">\(\yy\)</span> is denoted <span class="process-math">\(d(\xx,\yy)\text{,}\)</span> and defined as</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
d(\xx,\yy) = \len{\xx-\yy}\text{.}
\end{equation*}
</div></article><article class="remark remark-like" id="remark-11"><h4 class="heading">
<span class="type">Remark</span><span class="space"> </span><span class="codenumber">3.1.9</span><span class="period">.</span>
</h4>
<p id="p-817">Using properties of the norm, we can show that this distance function meets the criteria of what's called a <em class="emphasis">metric</em>. A metric is any function that takes a pair of vectors (or points) as input, and returns a number as output, with the following properties:</p>
<ol class="decimal">
<li id="li-117"><p id="p-818"><span class="process-math">\(d(\xx,\yy)=d(\yy,\xx)\)</span> for any <span class="process-math">\(\xx,\yy\)</span></p></li>
<li id="li-118"><p id="p-819"><span class="process-math">\(d(\xx,\yy)\geq 0\text{,}\)</span> and <span class="process-math">\(d(\xx,\yy)=0\)</span> if and only if <span class="process-math">\(\xx=\yy\)</span></p></li>
<li id="li-119"><p id="p-820"><span class="process-math">\(d(\xx,\yy)\leq d(\xx,\zz)+d(\zz,\yy)\)</span> for any <span class="process-math">\(\xx,\yy,\zz\)</span></p></li>
</ol>
<p class="continuation">We leave it as an exercise to confirm that the distance function defined above is a metric.</p>
<p id="p-821">In more advanced courses (e.g. topology or analysis) you might go into detailed study of these structures. There are three interrelated structures: inner products, norms, and metrics. You might consider questions like: does every norm come from an inner product? Does every metric come from a norm? (No.) Things get even more interesting for infinite-dimensional spaces. Of special interest are spaces such as <em class="emphasis">Hilbert spaces</em> (a special type of infinite-dimensional inner product space) and <em class="emphasis">Banach spaces</em> (a special type of infinite-dimensional normed space).</p></article><article class="exercise exercise-like" id="exercise-66"><h4 class="heading">
<span class="type">Exercise</span><span class="space"> </span><span class="codenumber">3.1.10</span><span class="period">.</span>
</h4>
<div class="runestone "><ul data-component="multiplechoice" id="" data-multipleanswers="true" data-random="">
<p id="p-822">Select all vectors that are orthogonal to the vector <span class="process-math">\((2,1,-3)\)</span></p>
<li data-component="answer" id="_opt_a" data-correct=""><p id="p-823"><span class="process-math">\((1,1,1)\)</span></p></li>
<li data-component="feedback" id="_opt_a"><p id="p-824">Yes! <span class="process-math">\(2(1)+1(1)-3(1)=0\text{.}\)</span></p></li>
<li data-component="answer" id="_opt_b"><p id="p-825"><span class="process-math">\((3,1,2)\)</span></p></li>
<li data-component="feedback" id="_opt_b"><p id="p-826">You should find that the dot product is <span class="process-math">\(1\text{,}\)</span> not <span class="process-math">\(0\text{,}\)</span> so these vectors are not orthogonal.</p></li>
<li data-component="answer" id="_opt_c"><p id="p-827"><span class="process-math">\((0,0)\)</span></p></li>
<li data-component="feedback" id="_opt_c"><p id="p-828">You might be tempted to say that the zero vector is orthoginal to everything, but we can't compare vectors from different vector spaces!</p></li>
<li data-component="answer" id="_opt_d" data-correct=""><p id="p-829"><span class="process-math">\((0,-3,-1)\)</span></p></li>
<li data-component="feedback" id="_opt_d"><p id="p-830">Yes! We have to be careful of signs here: <span class="process-math">\(2(0)+1(-3)+(-3)(-1)=0-3+3=0\text{.}\)</span></p></li>
</ul></div></article><article class="exercise exercise-like" id="exercise-67"><h4 class="heading">
<span class="type">Exercise</span><span class="space"> </span><span class="codenumber">3.1.11</span><span class="period">.</span>
</h4>
<div class="runestone "><ul data-component="multiplechoice" data-multipleanswers="false" id="">
<p id="p-831">If <span class="process-math">\(\uu\)</span> is orthogonal to <span class="process-math">\(\vv\)</span> and <span class="process-math">\(\vv\)</span> is orthogonal to <span class="process-math">\(\ww\text{,}\)</span> then <span class="process-math">\(\uu\)</span> is orthoginal to <span class="process-math">\(\ww\text{.}\)</span></p>
<li data-component="answer" id="_opt_t"><p>True.</p></li>
<li data-component="feedback" id="_opt_t"><p id="p-832">Consider <span class="process-math">\(\uu=(1,0,0)\text{,}\)</span> <span class="process-math">\(\vv=(0,1,0)\text{,}\)</span> and <span class="process-math">\(\ww=(1,0,1)\text{.}\)</span></p></li>
<li data-component="answer" id="_opt_f" data-correct=""><p>False.</p></li>
<li data-component="feedback" id="_opt_f"><p id="p-832">Consider <span class="process-math">\(\uu=(1,0,0)\text{,}\)</span> <span class="process-math">\(\vv=(0,1,0)\text{,}\)</span> and <span class="process-math">\(\ww=(1,0,1)\text{.}\)</span></p></li>
</ul></div></article></section><section class="subsection" id="subsec-ortho-sets"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">3.1.2</span> <span class="title">Orthogonal sets of vectors</span>
</h3>
<p id="p-833">In <a href="ch-vector-space.html" class="internal" title="Chapter 1: Vector spaces">Chapter 1</a>, we learn that linear independence and span are important concepts associated to a set of vectors. In this chapter, we learn what it means for a set of vectors to be <em class="emphasis">orthogonal</em>, and try to understand why this concept is just as important as independence and span.</p>
<article class="definition definition-like" id="def-ortho-set"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">3.1.12</span><span class="period">.</span>
</h4>
<p id="p-834">A set of vectors <span class="process-math">\(\{\vv_1,\vv_2,\ldots, \vv_k\}\)</span> in <span class="process-math">\(\R^n\)</span> is called <dfn class="terminology">orthogonal</dfn> if:</p>
<ul class="disc">
<li id="li-120"><p id="p-835"><span class="process-math">\(\vv_i\neq \zer\)</span> for each <span class="process-math">\(i=1,2\ldots, k\)</span></p></li>
<li id="li-121"><p id="p-836"><span class="process-math">\(\vv_i\dotp\vv_j = 0\)</span> for all <span class="process-math">\(i\neq j\)</span></p></li>
</ul></article><article class="exercise exercise-like" id="ex-orthogonal-set"><h4 class="heading">
<span class="type">Exercise</span><span class="space"> </span><span class="codenumber">3.1.13</span><span class="period">.</span>
</h4>
<p id="p-837">Show that the following is an orthogonal subset of <span class="process-math">\(\R^4\text{.}\)</span></p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\{(1,0,1,0), (-1,0,1,1), (1,1,-1,2)\}
\end{equation*}
</div>
<p class="continuation">Can you find a fourth vector that is orthogonal to each vector in this set?</p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-31" id="hint-31"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-31"><div class="hint solution-like"><p id="p-838">The dot product of the fourth vector with each vector above must be zero. Can you turn this requirement into a system of equations?</p></div></div>
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-47" id="solution-47"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-47"><div class="solution solution-like">
<p id="p-839">Clearly, all three vectors are nonzero. To confirm the set is orthogonal, we simply compute dot products:</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-44">
\begin{align*}
(1,0,1,0)\dotp (-1,0,1,1)\amp =-1+0+1+0=0\\
(-1,0,1,1)\dotp (1,1,-1,2)\amp =-1+0-1+2=0\\
(1,0,1,0)\dotp (1,1,-1,2) \amp = 1+0-1+0=0\text{.}
\end{align*}
</div>
<p id="p-840">To find a fourth vector, we proceed as follows. Let <span class="process-math">\(\xx=(a,b,c,d)\text{.}\)</span> We want <span class="process-math">\(\xx\)</span> to be orthogonal to the three vectors in our set. Computing dot products, we must have:</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-45">
\begin{align*}
(a,b,c,d)\dotp (1,0,1,0) \amp = a+c=0 \\
(a,b,c,d)\dotp (-1,0,1,1) \amp = -a+c+d=0 \\
(a,b,c,d)\dotp (1,1,-1,2) \amp = a+b-c+2d=0\text{.}
\end{align*}
</div>
<p class="continuation">This is simply a homogeneous system of three equations in four variables. Using the Sage cell below, we find that our vector must satisfy <span class="process-math">\(a=\frac12 d, b = -3d, c=-\frac12 d\text{.}\)</span></p>
<pre class="ptx-sagecell hidden-sagecell-sage" id="sage-45"><script type="text/x-sage">from sympy import Matrix, init_printing
init_printing()
A=Matrix(3,4,[1,0,1,0,-1,0,1,1,1,1,-1,2])
A.rref()
</script></pre>
<p id="p-841">One possible nonzero solution is to take <span class="process-math">\(d=2\text{,}\)</span> giving <span class="process-math">\(\xx=(1,-6,-1,2)\text{.}\)</span> We'll leave the verification that this vector works as an exercise.</p>
</div></div>
</div></article><article class="exercise exercise-like" id="exercise-69"><h4 class="heading">
<span class="type">Exercise</span><span class="space"> </span><span class="codenumber">3.1.14</span><span class="period">.</span>
</h4>
<div class="runestone "><ul data-component="multiplechoice" data-multipleanswers="false" id="">
<p id="p-842">If <span class="process-math">\(\{\vv,\ww\}\)</span> and <span class="process-math">\(\{\xx,\yy\}\)</span> are orthogonal sets of vectors in <span class="process-math">\(\R^n\text{,}\)</span> then <span class="process-math">\(\{\vv,\ww,\xx,\yy\}\)</span> is an orthogonal set of vectors.</p>
<li data-component="answer" id="_opt_t"><p>True.</p></li>
<li data-component="feedback" id="_opt_t"><p id="p-843">Try to construct an example. The vector <span class="process-math">\(\xx\)</span> has to be orthogonal to <span class="process-math">\(\yy\text{,}\)</span> but is there any reason it has to be orthogonal to <span class="process-math">\(\vv\)</span> or <span class="process-math">\(\ww\text{?}\)</span></p></li>
<li data-component="answer" id="_opt_f" data-correct=""><p>False.</p></li>
<li data-component="feedback" id="_opt_f"><p id="p-843">Try to construct an example. The vector <span class="process-math">\(\xx\)</span> has to be orthogonal to <span class="process-math">\(\yy\text{,}\)</span> but is there any reason it has to be orthogonal to <span class="process-math">\(\vv\)</span> or <span class="process-math">\(\ww\text{?}\)</span></p></li>
</ul></div></article><p id="p-844">The requirement that the vectors in an orthogonal set be nonzero is partly because the alternative would be boring, and partly because it lets us state the following theorem.</p>
<article class="theorem theorem-like" id="thm-ortho-independent"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">3.1.15</span><span class="period">.</span>
</h4>
<p id="p-845">Any orthogonal set of vectors is linearly independent.</p></article><article class="hiddenproof" id="proof-40"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-40"><h4 class="heading"><span class="title">Strategy.</span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-40"><article class="hiddenproof"><p id="p-846">Any proof of linear independence should start by defining our set of vectors, and assuming that a linear combination of these vectors is equal to the zero vector, with the goal of showing that the scalars have to be zero.</p>
<p id="p-847">Set up the equation (say, <span class="process-math">\(c_1\vv_1+\cdots c_n\vv_n=\zer\)</span>), with the assumption that your set of vectors is orthogonal. What happens if you take the dot product of both sides with one of these vectors?</p></article></div>
<article class="hiddenproof" id="proof-41"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-41"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-41"><article class="hiddenproof"><p id="p-848">Suppose <span class="process-math">\(S=\{\vv_1,\vv_2,\ldots, \vv_k\}\)</span> is orthogonal, and suppose</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
c_1\vv_1+c_2\vv_2+\cdots + c_k\vv_k = \zer
\end{equation*}
</div>
<p class="continuation">for scalars <span class="process-math">\(c_1,c_2,\ldots, c_k\text{.}\)</span> Taking the dot product of both sides of the above equation with <span class="process-math">\(\vv_1\)</span> gives</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-46">
\begin{align*}
c_1(\vv_1\dotp \vv_1)+c_2(\vv_1\dotp \vv_2)+\cdots +c_k(\vv_1\dotp \vv_k) \amp =\vv_1\dotp \zer\\
c_1\len{\vv_1}^2+0+\cdots + 0\amp = 0 \text{.}
\end{align*}
</div>
<p class="continuation">Since <span class="process-math">\(\len{\vv_1}^2\neq 0\text{,}\)</span> we must have <span class="process-math">\(c_1=0\text{.}\)</span> We similarly find that all the remaining scalars are zero by taking the dot product with <span class="process-math">\(\vv_2,\ldots, \vv_k\text{.}\)</span></p></article></div>
<p id="p-849">Another useful consequence of orthogonality: in two dimensions, we have the Pythagorean Theorem for right-angled triangles. If the “legs” of the triangle are identified with vectors <span class="process-math">\(\xx\)</span> and <span class="process-math">\(\yy\text{,}\)</span> and the hypotenuse with <span class="process-math">\(\zz\text{,}\)</span> then <span class="process-math">\(\len{\xx}^2+\len{\yy}^2=\len{\zz}^2\text{,}\)</span> since <span class="process-math">\(\xx\dotp \yy=0\text{.}\)</span></p>
<p id="p-850">In <span class="process-math">\(n\)</span> dimensions, we have the following, which follows from the fact that all “cross terms” (dot products of different vectors) will vanish.</p>
<article class="theorem theorem-like" id="thm-pythagoras"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">3.1.16</span><span class="period">.</span>
</h4>
<p id="p-851">For any orthogonal set of vectors <span class="process-math">\(\{\xx_1,\ldots, \xx_k\}\)</span> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\len{\xx_1+\cdots +\xx_k}^2 = \len{\xx_1}^2+\cdots + \len{\xx_k}^2\text{.}
\end{equation*}
</div></article><article class="hiddenproof" id="proof-42"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-42"><h4 class="heading"><span class="title">Strategy.</span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-42"><article class="hiddenproof"><p id="p-852">Remember that</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\len{\xx_1+\cdots + \xx_k}^2 = (\xx_1+\cdots +\xx_k)\dotp (\xx_1+\cdots +\xx_k)\text{,}
\end{equation*}
</div>
<p class="continuation">and use the distributive property of the dot product, along with the fact that each pair of different vectors is orthogonal.</p></article></div>
<p id="p-853">Our final initial result about orthogonal sets of vectors relates to span. In general, we know that if <span class="process-math">\(\yy\in\spn\{\xx_1,\ldots, \xx_k\}\text{,}\)</span> then it is possible to solve for scalars <span class="process-math">\(c_1,\ldots, c_k\)</span> such that <span class="process-math">\(\yy=c_1\xx_1+\cdots+ c_k\xx_k\text{.}\)</span> The trouble is that finding these scalars generally involves setting up, and then solving, a system of linear equations. The great thing about orthogonal sets of vectors is that we can provide explicit formulas for the scalars.</p>
<article class="theorem theorem-like" id="thm-fourier-expansion"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">3.1.17</span><span class="period">.</span><span class="space"> </span><span class="title">Fourier expansion theorem.</span>
</h4>
<p id="p-854">Let <span class="process-math">\(S=\{\vv_1,\vv_2,\ldots, \vv_k\}\)</span> be an orthogonal set of vectors. For any <span class="process-math">\(\yy\in \spn S\text{,}\)</span> we have</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\yy = \left(\frac{\yy\dotp\mathbf{v}_1}{\vv_1\dotp\vv_1}\right)\vv_1+
\left(\frac{\yy\dotp\mathbf{v}_2}{\vv_2\dotp\vv_2}\right)\vv_2+\cdots +
\left(\frac{\yy\dotp\mathbf{v}_k}{\vv_k\dotp\vv_k}\right)\vv_k\text{.}
\end{equation*}
</div></article><article class="hiddenproof" id="proof-43"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-43"><h4 class="heading"><span class="title">Strategy.</span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-43"><article class="hiddenproof"><p id="p-855">Take the same approach you used in the proof of <a href="" class="xref" data-knowl="./knowl/thm-ortho-independent.html" title="Theorem 3.1.15">Theorem 3.1.15</a>, but this time, with a nonzero vector on the right-hand side.</p></article></div>
<article class="hiddenproof" id="proof-44"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-44"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-44"><article class="hiddenproof"><p id="p-856">Let <span class="process-math">\(\yy=c_1\vv_1+\cdots + c_k\vv_k\text{.}\)</span> Taking the dot product of both sides of this equation with <span class="process-math">\(\vv_i\)</span> gives</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vv_i\dotp\yy = c_i(\vv_i\dotp\vv_i)\text{,}
\end{equation*}
</div>
<p class="continuation">since the dot product of <span class="process-math">\(\vv_i\)</span> with <span class="process-math">\(\vv_j\)</span> for <span class="process-math">\(i\neq j\)</span> is zero.</p></article></div>
<p id="p-857">One use of <a href="" class="xref" data-knowl="./knowl/thm-fourier-expansion.html" title="Theorem 3.1.17: Fourier expansion theorem">Theorem 3.1.17</a> is determining whether or not a given vector is in the span of an orthogonal set. If it is in the span, then its coefficients must satisfy the Fourier expansion formula. Therefore, if we compute the right hand side of the above formula and do not get our original vector, then that vector must not be in the span.</p>
<article class="exercise exercise-like" id="ex-test-span"><h4 class="heading">
<span class="type">Exercise</span><span class="space"> </span><span class="codenumber">3.1.18</span><span class="period">.</span>
</h4>
<p id="p-858">Determine whether or not the vectors <span class="process-math">\(\vv=(1,-4,3,-11), \ww=(3,1,-4,2)\)</span> belong to the span of the vectors <span class="process-math">\(\xx_1=(1,0,1,0), \xx_2=(-1,0,1,1), \xx_3=(1,1,-1,2)\text{.}\)</span></p>
<p id="p-859">(We confirmed that these vectors form an orthogonal set in <a href="" class="xref" data-knowl="./knowl/ex-orthogonal-set.html" title="Exercise 3.1.13">Exercise 3.1.13</a>.)</p>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-48" id="solution-48"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-48"><div class="solution solution-like">
<p id="p-860">We compute</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-47">
\begin{align*}
\left(\frac{\vv\dotp\xx_1}{\len{\xx_1}^2}\right)\xx_1
\amp +\left(\frac{\vv\dotp\xx_2}{\len{\xx_2}^2}\right)\xx_2
+\left(\frac{\vv\dotp\xx_3}{\len{\xx_3}^2}\right)\xx_3\\
\amp = \frac{4}{2}\xx_1+\frac{-9}{3}\xx_2+\frac{-28}{7}\xx_3\\
\amp = 2(1,0,1,0)-3(-1,0,1,1)-4(1,1,-1,2)\\
\amp = (1,-4,3,-11) = \vv\text{,}
\end{align*}
</div>
<p class="continuation">so <span class="process-math">\(\vv\in\spn\{\xx_1,\xx_2,\xx_3\}\text{.}\)</span></p>
<p id="p-861">On the other hand, repeating the same calculation with <span class="process-math">\(\ww\text{,}\)</span> we find</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-48">
\begin{align*}
\left(\frac{\vv\dotp\xx_1}{\len{\xx_1}^2}\right)\xx_1
\amp +\left(\frac{\vv\dotp\xx_2}{\len{\xx_2}^2}\right)\xx_2
+\left(\frac{\vv\dotp\xx_3}{\len{\xx_3}^2}\right)\xx_3\\
\amp =\frac12 (1,0,1,0)-\frac53 (-1,0,1,1) +\frac47 (1,1,-1,2)\\
\amp = \left(\frac{73}{42},\frac47,-\frac{115}{42},-\frac{11}{21}\right)\neq \ww\text{,}
\end{align*}
</div>
<p class="continuation">so <span class="process-math">\(\ww\notin\spn\{\xx_1,\xx_2,\xx_3\}\text{.}\)</span></p>
<p id="p-862">Soon, we'll see that the quantity we computed when showing that <span class="process-math">\(\ww\notin\spn\{\xx_1,\xx_2,\xx_3\}\)</span> is, in fact, the <em class="emphasis">orthogonal projection</em> of <span class="process-math">\(\ww\)</span> onto the subspace <span class="process-math">\(\spn\{\xx_1,\xx_2,\xx_3\}\text{.}\)</span></p>
</div></div>
</div></article><p id="p-863">The Fourier expansion is especially simple if our basis vectors have norm one, since the denominators in each coefficient disappear. Recall that a <dfn class="terminology">unit vector</dfn> in <span class="process-math">\(\R^n\)</span> is any vector <span class="process-math">\(\xx\)</span> with <span class="process-math">\(\len{\xx}=1\text{.}\)</span> For any nonzero vector <span class="process-math">\(\vv\text{,}\)</span> a <em class="emphasis">unit vector</em> (that is, a vector of norm one) in the direction of <span class="process-math">\(\vv\)</span> is given by</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\hat{u} = \frac{1}{\len{\vv}}\vv\text{.}
\end{equation*}
</div>
<p class="continuation">We often say that the vector <span class="process-math">\(\uu\)</span> is <em class="emphasis">normalized</em>. (The convention of using a “hat” for unit vectors is common but not universal.)</p>
<article class="exercise exercise-like" id="exercise-71"><h4 class="heading">
<span class="type">Exercise</span><span class="space"> </span><span class="codenumber">3.1.19</span><span class="period">.</span>
</h4>
<div class="runestone"><ul data-component="dragndrop" data-question_label="" style="visibility: hidden;" id="">
<span data-subcomponent="question"><p id="p-864">Match each vector on the left with a parallel unit vector on the right.</p></span><li data-subcomponent="draggable" id="_drag1"><span class="process-math">\(\langle 2, -1, 2\rangle\)</span></li>
<li data-subcomponent="dropzone" for="_drag1"><span class="process-math">\(\left\langle \frac23, -\frac13, \frac23\right\rangle\)</span></li>
<li data-subcomponent="draggable" id="_drag2"><span class="process-math">\(\langle 3,0,-4\rangle\)</span></li>
<li data-subcomponent="dropzone" for="_drag2"><span class="process-math">\(\left\langle \frac35, 0,-\frac45\right\rangle\)</span></li>
<li data-subcomponent="draggable" id="_drag3"><span class="process-math">\(\langle 1,2,1\)</span></li>
<li data-subcomponent="dropzone" for="_drag3"><span class="process-math">\(\left\langle \frac{1}{\sqrt{6}},\frac{2}{\sqrt{6}},\frac{1}{\sqrt{6}}\right\rangle\)</span></li>
<li data-subcomponent="draggable" id="_drag4"><span class="process-math">\(\langle 2,0,1\rangle\)</span></li>
<li data-subcomponent="dropzone" for="_drag4"><span class="process-math">\(\left\langle \frac{2}{\sqrt{5}},0,\frac{1}{\sqrt{5}}\right\rangle\)</span></li>
</ul></div></article><article class="definition definition-like" id="def-onb"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">3.1.20</span><span class="period">.</span>
</h4>
<p id="p-865">A basis <span class="process-math">\(B\)</span> of <span class="process-math">\(\R^n\)</span> is called an <dfn class="terminology">orthonormal basis</dfn> if <span class="process-math">\(B\)</span> is orthogonal, and all the vectors in <span class="process-math">\(B\)</span> are unit vectors.</p></article><article class="example example-like" id="example-11"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">3.1.21</span><span class="period">.</span>
</h4>
<p id="p-866">In <a href="" class="xref" data-knowl="./knowl/ex-orthogonal-set.html" title="Exercise 3.1.13">Exercise 3.1.13</a> we saw that the set</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/ex-orthogonal-set.html">
\begin{equation*}
\{(1,0,1,0), (-1,0,1,1), (1,1,-1,2),(1,-6,-1,2)\}
\end{equation*}
</div>
<p class="continuation">is orthogonal. Since it's orthogonal, it must be independent, and since it's a set of four independent vectors in <span class="process-math">\(\R^4\text{,}\)</span> it must be a basis. To get an orthonormal basis, we normalize each vector:</p>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/ex-orthogonal-set.html" id="md-49">
\begin{align*}
\hat{u}_1 \amp = \frac{1}{\sqrt{1^2+0^2+1^2+0^2}}(1,0,1,0) = \frac{1}{\sqrt{2}}(1,0,1,0)\\
\hat{u}_2 \amp = \frac{1}{\sqrt{(-1)^2+0^2+1^2+1^2}}(-1,0,1,1,) = \frac{1}{\sqrt{3}}(-1,0,1,1)\\
\hat{u}_3 \amp = \frac{1}{\sqrt{1^2+1^2+(-1)^2+2^2}}(1,1,-1,2) = \frac{1}{\sqrt{7}}(1,1,-1,2)\\
\hat{u}_4 \amp = \frac{1}{\sqrt{1^2+(-6)^2+(-1)^2+2^2}}(1,-6,-1,2) = \frac{1}{\sqrt{42}}(1,-6,-1,2)\text{.}
\end{align*}
</div>
<p class="continuation">The set <span class="process-math">\(\{\hat{u}_1,\hat{u}_2,\hat{u}_3,\hat{u}_4\}\)</span> is then an orthonormal basis of <span class="process-math">\(\R^4\text{.}\)</span></p></article><p id="p-867">The process of creating unit vectors does typically introduce square root coefficients in our vectors. This can seem undesirable, but there remains value in having an orthonormal basis. For example, suppose we wanted to write the vector <span class="process-math">\(\vv=(3,5,-1,2)\)</span> in terms of our basis. We can quickly compute</p>
<div class="displaymath process-math" data-contains-math-knowls="" id="md-50">
\begin{align*}
\vv\dotp\hat{u}_1 \amp = \frac{3}{\sqrt{2}}-\frac{1}{\sqrt{2}}=\sqrt{2}\\
\vv\dotp\hat{u}_2 \amp = -\frac{3}{\sqrt{3}}-\frac{1}{\sqrt{3}}+\frac{2}{\sqrt{3}}=-\frac{2}{\sqrt{3}}\\
\vv\dotp\hat{u}_3 \amp = \frac{3}{\sqrt{7}}+\frac{5}{\sqrt{7}}+\frac{1}{\sqrt{7}}+\frac{4}{\sqrt{7}} = \frac{11}{\sqrt{7}}\\
\vv\dotp\hat{u}_4 \amp = \frac{3}{\sqrt{42}}-\frac{30}{\sqrt{42}}+\frac{1}{\sqrt{42}}+\frac{4}{\sqrt{42}} = -\frac{22}{\sqrt{42}}\text{,}
\end{align*}
</div>
<p class="continuation">and so</p>
<div class="displaymath process-math" data-contains-math-knowls="">
\begin{equation*}
\vv = \sqrt{2}\hat{u}_1-\frac{2}{\sqrt{3}}\hat{u}_2+\frac{11}{\sqrt{7}}\hat{u}_3-\frac{22}{\sqrt{42}}\hat{u}_4\text{.}
\end{equation*}
</div>
<p class="continuation">There's still work to be done, but it is comparatively simpler than solving the corresponding system of equations.</p></section></section></div></main>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/components/prism-core.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.26.0/plugins/autoloader/prism-autoloader.min.js"></script>
</body>
</html>
