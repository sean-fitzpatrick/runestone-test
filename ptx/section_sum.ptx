<?xml version="1.0" encoding="UTF-8" ?>

<section xml:id="sec-subspace-combine">
  <title>New subspaces from old</title>
  <p>
    Let <m>V</m> be a finite-dimensional vector space, and let <m>U,W</m> be subspaces of <m>V</m>.
    In what ways can we combine <m>U</m> and <m>W</m> to obtain new subspaces?
  </p>

  <p>
    At first, we might try set operations: union, intersection, and difference.
    The set difference we can rule out right away: since <m>U</m> and <m>W</m> must both contain the zero vector,
    <m>U\setminus W</m> cannot.
  </p>

  <p>
    What about the union, <m>U\cup W</m>? Before trying to understand this in general,
    let's try a concrete example: take <m>V=\R^2</m>, and let <m>U=\{(x,0)\,|,x\in \R\}</m> (the <m>x</m> axis, essentially),
    and <m>W=\{(0,y)\,|\,y\in\R\}</m> (the <m>y</m> axis). Is their union a subspace?
  </p>

  <exercise>
    <statement correct="no">
      <p>
        The union of the <q><m>x</m> axis</q> and <q><m>y</m> axis</q> in <m>\R^2</m> is a subspace of <m>\R^2</m>.
      </p>
    </statement>
    <feedback>
      <p>
        Any subspace has to be closed under addition.
        If we add the vector <m>(1,0)</m> (which lies along the <m>x</m> axis)
        to the vector <m>(0,1)</m> (which lies along the <m>y</m> axis),
        we get the vector <m>(1,1)</m>, which does not lie along either axis.
      </p>
    </feedback>
  </exercise>

  <p>
    With a motivating example under our belts, we can try to tackle the general result.
    (Note that this result remains true even if <m>V</m> is infinite-dimensional!)
  </p>

  <theorem xml:id="thm-subspace-union">
    <statement>
      <p>
        Let <m>U</m> and <m>W</m> be subspaces of a vector space <m>V</m>.
        Then <m>U\cup W</m> is a subspace of <m>V</m> if and only if <m>U\subseteq W</m> or <m>W\subseteq U</m>.
      </p>
    </statement>
    <proof>
      <title>Strategy</title>
      <p>
        We have an <q>if and only</q> if statement, which means we have to prove two directions:
        <ol>
          <li>
            <p>
              If <m>U\subseteq W</m> or <m>W\subseteq U</m>, then <m>U\cup W</m> is a subspace.
            </p>
          </li>
          <li>
            <p>
              If <m>U\cup W</m> is a subspace, then <m>U\subseteq W</m> or <m>W\subseteq U</m>.
            </p>
          </li>
        </ol>
      </p>

      <p>
        The first direction is the easy one: if <m>U\subseteq W</m>, what can you say about <m>U\cup W</m>?
      </p>
      <p>
        For the other direction, it's not clear how to get started with our hypothesis.
        When a direct proof seems difficult, remember that we can also try proving the contrapositive:
        If <m>U\not\subseteq W</m> and <m>W\not\subseteq U</m>, then <m>U\cup W</m> is not a subspace.
      </p>

      <p>
        Now we have more to work with: negation turns the <q>or</q> into an <q>and</q>,
        and proving that something is not a subspace is easier: we just have to show that one part of the subspace test fails.
        As our motivating example suggests, we should expect closure under addition to be the condition that fails.
      </p>

      <p>
        To get started, we need to answer one more question:
        if <m>U</m> is not a subset of <m>W</m>, what does that tell us?
      </p>

      <p>
        An important point to keep in mind with this proof:
        closure under addition means that if a subspace contains <m>\uu</m> and <m>\ww</m>, then it must contain <m>\uu+\ww</m>.
        But if a subspace contains <m>\uu+\ww</m>, that does <em>not</em> mean it has to contain <m>\uu</m> and <m>\ww</m>.
        As an example, consider the subspace <m>\{(x,x)\,|\,x\in\R\}</m> of <m>\R^2</m>.
        It contains the vector <m>(1,1)=(1,0)+(0,1)</m>, but it does not contain <m>(1,0)</m> or <m>(0,1)</m>.
      </p>
    </proof>
    <proof>
      <p>
        Suppose <m>U\subseteq W</m> or <m>W\subseteq U</m>. In the first case,
        <m>U\cup W=W</m>, and in the second case, <m>U\cup W=U</m>.
        Since both <m>U</m> and <m>W</m> are subspaces, <m>U\cup W</m> is a subspace.
      </p>

      <p>
        Now, suppose that <m>U\not\subseteq W</m>, and <m>W\not\subseteq U</m>.
        Since <m>U\not\subseteq W</m>, there must be some element <m>\uu\in U</m> such that <m>\uu\notin W</m>.
        Since <m>W\not\subseteq U</m>, there must be some element <m>\ww\in W</m> such that <m>\ww\notin U</m>.
        We know that <m>\uu,\ww\in U\cup W</m>, so we consider the sum, <m>\uu+\ww</m>.
      </p>

      <p>
        If <m>\uu+\ww\in U\cup W</m>, then <m>\uu+\ww\in U</m>, or <m>\uu+\ww\in W</m>.
        Suppose <m>\uu+\ww\in U</m>. Since <m>\uu \in U</m> and <m>U</m> is a subspace, <m>-\uu\in U</m>.
        Since <m>-\uu, \uu+\ww\in U</m> and <m>U</m> is a subspace,
        <me>
          -\uu+(\uu+\ww)=(-\uu+\uu)+\ww=\zer+\ww=\ww \in U
        </me>.
        But we assumed that <m>\ww\notin U</m>, so it must be that <m>\uu+\ww\notin U</m>.
      </p>

      <p>
        By a similar argument, if <m>\uu+\ww\in W</m>, we can conclude that <m>\uu\in W</m>,
        contradicting the assumption that <m>\uu\notin W</m>.
        So <m>\uu+\ww</m> does not belong to <m>U</m> or <m>W</m>, so it cannot belong to <m>U\cup W</m>.
        Since <m>U\cup W</m> is not closed under addition, it is not a subspace.
      </p>
    </proof>
  </theorem>

  <p>
    This leaves us with intersection. Will it fail as well?
    Fortunately, the answer is no: this operation actually gives us a subspace.
  </p>

  <theorem xml:id="thm-subspace-intersection">
    <statement>
      <p>
        If <m>U</m> and <m>W</m> are subspaces of a vector space <m>V</m>,
        then <m>U\cap W</m> is a subspace.
      </p>
    </statement>
    <proof>
      <title>Strategy</title>
      <p>
        The key here is that the intersection contains only those vectors that belong to <em>both</em> subspaces.
        So any operation (addition, scalar multiplication) that we do in <m>U\cap W</m>
        can be viewed as taking place in either <m>U</m> or <m>W</m>,
        and we know that these are subspaces. After this observation, the rest is the <xref ref="thm-subspace-test" text="title"/>.
      </p>
    </proof>
    <proof>
      <p>
        Let <m>U</m> and <m>W</m> be subspaces of <m>V</m>.
        Since <m>\zer\in U</m> and <m>\zer \in W</m>, we have <m>\zer\in U\cap W</m>.
        Now, suppose <m>\xx,\yy\in U\cap W</m>.
        Then <m>\xx,\yy\in U</m>, and <m>\xx,\yy\in W</m>.
        Since <m>\xx,\yy\in U</m> and <m>U</m> is a subspace, <m>\xx+\yy\in U</m>.
        Similarly, <m>\xx+\yy\in W</m>, so <m>\xx+\yy\in U\cap W</m>.
        If <m>c</m> is any scalar, then <m>c\xx</m> is in both <m>U</m> and <m>W</m>,
        since both sets are subspaces, and therefore, <m>c\xx\in U\cap W</m>.
        By the <xref ref="thm-subspace-test" text="title"/>, <m>U\cap W</m> is a subspace.
      </p>
    </proof>
  </theorem>


  <p>
    The intersection of two subspaces gives us a subspace,
    but it is a smaller subspace, contained in the two subspaces we're intersecting.
    Given subspaces <m>U</m> and <m>W</m>, is there a way to construct a <em>larger</em> subspace that contains them?
    We know that <m>U\cup W</m> doesn't work, because it isn't closed under addition.
    But what if we started with <m>U\cup W</m>, and threw in all the missing sums? This leads to a definition:
  </p>

  <definition xml:id="def-subspace-sum">
    <statement>
      <p>
        Let <m>U</m> and <m>W</m> be subspaces of a vector space <m>V</m>.
        We define the sum <m>U+W</m> of these subspaces by
        <me>
          U+W = \{\uu+\ww \,|\, \uu\in U \text{ and } \ww\in W\}
        </me>.
      </p>
    </statement>
  </definition>

  <p>
    It turns out that this works! Not only is <m>U+W</m> a subspace of <m>V</m>,
    it is the <em>smallest</em> subspace containing both <m>U</m> and <m>W</m>.
  </p>

  <theorem xml:id="thm-subspace-sum">
    <statement>
      <p>
        Let <m>U</m> and <m>W</m> be subspaces of a vector space <m>V</m>.
        Then the sum <m>U+W</m> is a subspace of <m>V</m>,
        and if <m>X</m> is any subspace of <m>V</m> that contains <m>U</m> and <m>W</m>,
        then <m>U+W\subseteq X</m>.
      </p>
    </statement>
    <proof>
      <title>Strategy</title>
      <p>
        The key to working with <m>U+W</m> is to understand how to work with the definition.
        If we say that <m>\xx\in U+W</m>, then we are saying there exist vectors
        <m>\uu\in U</m> and <m>\ww\in W</m> such that <m>\uu+\ww=\xx</m>.
      </p>

      <p>
        We prove that <m>U+W</m> is a subspace using this observation and the subspace test.
      </p>

      <p>
        To prove the second part, we assume that <m>U\subseteq X</m> and <m>W\subseteq X</m>.
        We then choose an element <m>\xx\in U+W</m>, and using the idea above, show that <m>\xx\in X</m>.
      </p>
    </proof>
    <proof>
      <p>
        Let <m>U,W</m> be subspaces. Since <m>\zer=\zer+\zer</m>, with <m>\zer\in U</m> and <m>\zer \in W</m>,
        we see that <m>\zer\in U+W</m>.
      </p>

      <p>
        Suppose that <m>\xx,\yy\in U+W</m>. Then there exist <m>\uu_1,\uu_2\in U</m>,
        and <m>\ww_1,\ww_2\in W</m>, with <m>\uu_1+\ww_1=\xx</m>, and <m>\uu_2+\ww_2=\yy</m>.
        Then
        <me>
          \xx+\yy = (\uu_1+\ww_1)+(\uu_2+\ww_2)=(\uu_1+\uu_2)+(\ww_1+\ww_2)
        </me>,
        and we know that <m>\uu_1+\uu_2\in U</m>, and <m>\ww_1+\ww_2\in W</m>,
        since <m>U</m> and <m>W</m> are subspaces.
        Since <m>\xx+\yy</m> can be written as the sum of an element of <m>U</m>
        and an element of <m>W</m>, we have <m>\xx+\yy\in U+W</m>.
      </p>

      <p>
        If <m>c</m> is any scalar, then
        <me>
          c\xx=c(\uu_1+\ww_1)=c\uu_1+c\ww_1\in U+W
        </me>,
        since <m>c\uu_1\in U</m> and <m>c\ww_1\in W</m>.
      </p>

      <p>
        Since <m>U+W</m> contains <m>\zer</m>, and is closed under both addition and scalar multiplication,
        it is a subspace.
      </p>

      <p>
        Now, suppose <m>X</m> is a subspace of <m>V</m> such that <m>U\subseteq X</m> and <m>W\subseteq X</m>.
        Let <m>\xx\in U+W</m>. Then <m>\xx=\uu+\ww</m> for some <m>\uu\in U</m> and <m>\ww\in W</m>.
        Since <m>\uu\in U</m> and <m>U\subseteq X</m>, <m>\uu\in X</m>.
        Similarly, <m>\ww\in X</m>. Since <m>X</m> is a subspace, it is closed under addition,
        so <m>\uu+\ww=\xx\in X</m>. Therefore, <m>U+W\subseteq X</m>.
      </p>
    </proof>

  </theorem>

  <p>
    By choosing bases for two subspaces <m>U</m> and <m>W</m> of a finite-dimensional vector space,
    we can obtain the following cool dimension-counting result:
  </p>

  <theorem xml:id="thm-sum-dimension">
    <statement>
      <p>
        Let <m>U</m> and <m>W</m> be subspaces of a finite-dimensional vector space <m>V</m>.
        Then <m>U+W</m> is finite-dimensional, and
        <me>
          \dim(U+W)=\dim U + \dim W - \dim(U\cap W)
        </me>.
      </p>
    </statement>
    <proof>
      <title>Strategy</title>
      <p>
        This is a proof that would be difficult (if not impossible) without using a basis.
        Your first thought might be to choose bases for the subspaces <m>U</m> and <m>W</m>,
        but this runs into trouble: some of the basis vectors for <m>U</m> might be in <m>W</m>,
        and vice-versa.
      </p>
      <p>
        Of course, those vectors will be in <m>U\cap W</m>, but it gets hard to keep track:
        without more information (and we have none, since we want to be completely general),
        how do we tell which basis vectors are in the intersection, and how many?
      </p>
      <p>
        Instead, we <em>start</em> with a basis for <m>U\cap W</m>.
        This is useful, because <m>U\cap W</m> is a subspace of both <m>U</m> and <m>W</m>.
        So any basis for <m>U\cap W</m> can be extended to a basis of <m>U</m>,
        and it can also be extended to a basis of <m>W</m>.
      </p>
      <p>
        The rest of the proof relies on making sure that neither of these extensions have any vectors in common,
        and that putting everything together gives a basis for <m>U+W</m>.
        (This amounts to going back to the definition of a basis:
        we need to show that it's linearly independent, and that it spans <m>U+W</m>.)
      </p>
    </proof>
    <proof>
      <p>
        Let <m>B_1 = \{\xx_1,\ldots, \xx_k\}</m> be a basis for <m>U\cap W</m>.
        Extend <m>B_1</m> to a basis <m>B_2=\{\xx_1,\ldots, \xx_k,\uu_1,\ldots,\uu_m\}</m> of <m>U</m>,
        and to a basis <m>B_3=\{\xx_1,\ldots, \xx_k,\ww_1,\ldots, \ww_n\}</m> of <m>W</m>.
        Note that we have <m>\dim (U\cap W)=k</m>, <m>\dim U = k+m</m>, and <m>\dim W=k+n</m>.
      </p>
      <p>
        Now, consider the set <m>B=\{\xx_1,\ldots, \xx_k,\uu_1,\ldots, \uu_m,\ww_1,\ldots, \ww_n\}</m>.
        We claim that <m>B</m> is a basis for <m>U+W</m>.
        We know that <m>B_2</m> is linearly independent, since it's a basis for <m>U</m>,
        and that <m>B=B_2\cup\{\ww_1,\ldots, \ww_n\}</m>.
        It remains to show that none of the <m>\ww_i</m> are in the span of <m>B_2</m>;
        if so, then <m>B</m> is independent by <xref ref="lemma-independent"/>.
      </p>
      <p>
        Since <m>\spn B_2=U</m>, it suffices to show that none of the <m>\ww_i</m> belong to <m>U</m>.
        But we know that <m>\ww_i\in W</m>, so if <m>\ww_i\in U</m>, then <m>\ww_i\in U\cap W</m>.
        But if <m>\ww_i\in U\cap W</m>, then <m>\ww_i\in \spn B_1</m>,
        which would imply that <m>B_3</m> is linearly dependent,
        and since <m>B_3</m> is a basis, this is impossible.
      </p>
      <p>
        Next, we need to show that <m>\spn B = U+W</m>.
        Let <m>\vv\in U+W</m>; then <m>\vv=\uu+\ww</m> for some <m>\uu\in U</m> and <m>\ww\in W</m>.
        Since <m>\uu\in U</m>, there exist scalars <m>a_1,\ldots, a_k, b_1,\ldots, b_m</m> such that
        <me>
          \uu=a_1\xx_1+\cdots + a_k\xx_k+b_1\uu_1+\cdots+b_m\uu_m
        </me>,
        and since <m>\ww\in W</m>, there exist scalars <m>c_1,\ldots, c_k,d_1,\ldots, d_n</m> such that
        <me>
          \ww=c_1\xx_1+\cdots +c_k\xx_k+d_1\ww_1+\cdots +d_n\ww_n
        </me>.
        Thus,
        <me>
          \vv = \uu+\ww = (a_1+c_1)\xx_1+\cdots+(a_k+c_k)\xx_k+b_1\uu_1+\cdots +b_m\uu_m+d_1\ww_1+\cdots + d_n\ww_n
        </me>,
        which shows that <m>\vv\in \spn B</m>.
      </p>
      <p>
        Finally, we check that this gives the dimension as claimed. We have
        <me>
          \dim U + \dim W - \dim (U\cap W) = (k+m)+(k+n)-k=k+m+n=\dim(U+W)
        </me>,
        since there are <m>k</m> vectors in <m>B_1</m>, <m>k+m</m> vectors in <m>B_2</m>,
        <m>k+n</m> vectors in <m>B_3</m>, and <m>k+m+n</m> vectors in <m>B</m>.
      </p>
    </proof>
  </theorem>

  <p>
    Notice how a vector <m>\vv\in U+W</m> can be written as a sum of a vector in <m>U</m> and a vector <m>W</m>,
    but <em>not uniquely</em>, in general: in the above proof,
    we can change the values of the coefficients <m>a_i</m> and <m>c_i</m>,
    as long as the sum <m>a_i+c_i</m> remains unchanged.
    Note that these are the coefficients of the basis vectors for <m>U\cap W</m>,
    so we can avoid this ambiguity if <m>U</m> and <m>W</m> have no nonzero vectors in common.
  </p>

  <exercise>
    <introduction>
      <p>
        Let <m>V=\R^3</m>, and let <m>U=\{(x,y,0)\,|\,x,y,\in\R\}, W=\{(0,y,z)\,|\,y,z\in\R\}</m>
        be two subspaces.
      </p>
    </introduction>
    <task>
      <statement>
        <p>
          Determine the intersection <m>U\cap W</m>.
        </p>
      </statement>
      <solution>
        <p>
          If <m>(x,y,z)\in U</m>, then <m>z=0</m>, and if <m>(x,y,z)\in W</m>, then <m>x=0</m>.
          Therefore, <m>(x,y,z)\in U\cap W</m> if and only if <m>x=z=0</m>, so
          <m>U\cap W = \{(0,y,0)\,|\, y\in\R\}</m>.
        </p>
      </solution>
    </task>
    <task>
      <statement>
        <p>
          Write the vector <m>\vv=(1,1,1)</m> in the form <m>\vv=\uu+\ww</m>,
          where <m>\uu\in U</m> and <m>\ww\in W</m>, in at least two different ways.
        </p>
      </statement>
      <solution>
        <p>
          There are in fact infinitely many ways to do this. Three possible ways include:
          <md>
            <mrow>\vv \amp = (1,1,0)+(0,0,1) </mrow>
            <mrow> \amp = (1,0,0)+(0,1,1)</mrow>
            <mrow> \amp = \left(1,\frac12,0\right)+\left(0,\frac12,1\right)</mrow>
          </md>.
        </p>
      </solution>
    </task>
  </exercise>

  <definition xml:id="def-direct-sum">
    <statement>
      <p>
        Let <m>U</m> and <m>W</m> be subspaces of a vector space <m>V</m>.
        If <m>U\cap W =\{\zer\}</m>, we say that the sum <m>U+W</m>
        is a <term>direct sum</term>, which we denote by <m>U\oplus W</m>.
      </p>
    </statement>
  </definition>

  <p>
    If the sum is direct, then we have simply <m>\dim(U\oplus W) = \dim U + \dim W</m>.
    The other reason why direct sums are preferable, is that any <m>\vv\in U\oplus W</m>
    can be written <em>uniquely</em> as <m>\vv=\uu+\ww</m>
    where <m>\uu\in U</m> and <m>\ww\in W</m>, since we no longer have the ambiguity resulting from the basis vectors in <m>U\cap W</m>.
  </p>

  <theorem xml:id="thm-unique-sum">
    <statement>
      <p>
        For any subspaces <m>U,W</m> of a vector space <m>V</m>,
        <m>U\cap W = \{\zer\}</m> if and only if for every <m>\vv\in U+W</m>
        there exist unique <m>\uu\in U, \ww\in W</m> such that <m>\vv=\uu+\ww</m>.
      </p>
    </statement>
    <proof>
      <p>
        Suppose that <m>U\cap W = \{\zer\}</m>, and suppose that we have
        <m>\vv = \uu_1+\ww_1 = \uu_2+\ww_2</m>,
        for <m>\uu_1,\uu_2\in U,\ww_1,\ww_2\in W</m>.
        Then <m>\zer=(\uu_1-\uu_2)+(\ww_1-\ww_2)</m>,
        which implies that
        <me>
          \ww_1-\ww_2 = -(\uu_1-\uu_2)
        </me>.
        Now, <m>\uu=\uu_1-\uu_2\in U</m>,
        since <m>U</m> is a subspace, and similarly,
        <m>\ww=\ww_1-\ww_2\in W</m>.
        But we also have <m>\ww=-\uu</m>, which implies that <m>\ww\in U</m>.
        (Since <m>-\uu</m> is in <m>U</m>, and this is the same vector as <m>\ww</m>.)
        Therefore, <m>\ww\in U\cap W</m>, which implies that <m>\ww=\zer</m>,
        so <m>\ww_1=\ww_2</m>.
        But we must also then have <m>\uu=\zer</m>, so <m>\uu_1=\uu_2</m>.
      </p>

      <p>
        Conversely, suppose that every <m>\vv\in U+W</m> can be written uniquely as <m>\vv=\vec{u}+\ww</m>,
        with <m>\uu\in U</m> and <m>\ww\in W</m>. Suppose that <m>\mathbf{a}\in U\cap W</m>.
        Then <m>\mathbf{a}\in U</m> and <m>\mathbf{a}\in W</m>, so we also have <m>-\mathbf{a}\in W</m>,
        since <m>W</m> is a subspace.
        But then <m>\zer=\mathbf{a}+(-\mathbf{a})</m>, where <m>\mathbf{a}\in U</m> and <m>-\mathbf{a}\in W</m>.
        On the other hand, <m>\zer=\zer+\zer</m>,
        and <m>\zer</m> belongs to both <m>U</m> and <m>W</m>. It follows that <m>\mathbf{a}=\zer</m>.
        Since <m>\mathbf{a}</m> was arbitrary, <m>U\cap W = \{\zer\}</m>.
      </p>
    </proof>

  </theorem>

  <p>
    We end with one last application of the theory we've developed on the existence of a basis for a finite-dimensional vector space.
    As we continue on to later topics, we'll find that it is often useful to be able to decompose a vector space into a direct sum of subspaces.
    Using bases, we can show that this is always possible.
  </p>

  <theorem xml:id="thm-construct-complement">
    <statement>
      <p>
        Let <m>V</m> be a finite-dimensional vector space, and let <m>U</m> be any subspace of <m>V</m>.
        Then there exists a subspace <m>W\subseteq V</m> such that <m>U\oplus W = V</m>.
      </p>
    </statement>
    <proof>
      <p>
        Let <m>\{\uu_1,\ldots, \uu_m\}</m> be a basis of <m>U</m>.
        Since <m>U\subseteq V</m>, the set <m>\{\uu_1,\ldots, \uu_m\}</m>
        is a linearly independent subset of <m>V</m>.
        Since any linearly independent set can be extended to a basis of <m>V</m>,
        there exist vectors <m>\ww_1,\ldots,\ww_n</m> such that
        <me>
          \{\uu_1,\ldots, \uu_m,\ww_1,\ldots, \ww_n\}
        </me>
        is a basis of <m>V</m>.
      </p>

      <p>
        Now, let <m>W = \spn\{\ww_1,\ldots, \ww_n\}</m>.
        Then <m>W</m> is a subspace, and <m>\{\ww_1,\ldots, \ww_n\}</m>
        is a basis for <m>W</m>. (It spans, and must be independent since it's a subset of an independent set.)
      </p>

      <p>
        Clearly, <m>U+W=V</m>, since <m>U+W</m> contains the basis for <m>V</m> we've constructed.
        To show the sum is direct, it suffices to show that <m>U\cap W = \{\zer\}</m>.
        To that end, suppose that <m>\vv\in U\cap W</m>.
        Since <m>\vv\in U</m>, we have
        <me>
          \vv=a_1\uu_1+\cdots +a_m\uu_m
        </me>
        for scalars <m>a_1,\ldots, a_m</m>. Since <m>\vv\in W</m>, we can write
        <me>
          \vv=b_1\ww_1+\cdots + b_n\ww_n
        </me>
        for scalars <m>b_1,\ldots, b_n</m>. But then
        <me>
          \zer=\vv-\vv=a_1\uu_1+\cdots a_m\uu_m-b_1\ww_1-\cdots -b_n\ww_n.
        </me>
        Since <m>\{\uu_1,\ldots, \uu_m,\ww_1,\ldots, \ww_n\}</m> is a basis for <m>V</m>,
        it's independent, and therefore, all of the <m>a_i,b_j</m> must be zero, and therefore, <m>\vv=\zer</m>.

      </p>
    </proof>
  </theorem>

  <aside>
    <p>
      If a basis has been chosen for <m>V</m>,
      one way to construct a complement to a subspace <m>U</m> is to determine which elements of the basis for <m>V</m> are not in <m>U</m>.
      These vectors will form a basis for a complement of <m>U</m>.
    </p>
  </aside>

  <p>
    The subspace <m>W</m> constructed in the theorem above is called a <term>complement</term> of <m>U</m>.
    It is not unique; indeed, it depends on the choice of basis vectors.
    For example, if <m>U</m> is a one-dimensional subspace of <m>\R^2</m>; that is, a line,
    then any other non-parallel line through the origin provides a complement of <m>U</m>.
    Later we will see that an especially useful choice of complement is the <term>orthogonal complement</term>.
  </p>

  <definition xml:id="def-subspace-complement">
    <statement>
      <p>
        Let <m>U</m> be a subspace of a vector space <m>V</m>.
        We say that a subspace <m>W</m> of <m>V</m> is a <term>complement</term> of <m>U</m>
        if <m>U\oplus W=V</m>.
      </p>
    </statement>
  </definition>

  <exercise>
    <introduction>
      <p>
        Let <m>U</m> be the subspace of <m>P_3(\R)</m> consisting of all polynomials <m>p(x)</m> with <m>p(1)=0</m>.
      </p>
    </introduction>
    <task>
      <statement>
        <p>
          Determine a basis for <m>U</m>.
        </p>
      </statement>
      <hint>
        <p>
          Use the factor theorem.
        </p>
      </hint>
      <solution>
        <p>
          Since <m>p(1)=0</m>, we know that <m>p(x)=(x-1)q(x)</m>, for some <m>q(x)=ax^2+bx+c</m>.
          Thus, <m>p(x)=ax^2(x-1)+bx(x-1)+c(x-1)</m>, so a basis is given by
          <m>\{(x-1),x(x-1),x^2(x-1)\}</m>.
        </p>
        <p>
          (Another option is <m>\{(x-1),(x-1)^2,(x-1)^3\}</m>.)
        </p>
      </solution>
    </task>
    <task>
      <statement>
        <p>
          Find a complement of <m>U</m>.
        </p>
      </statement>
      <hint>
        <p>
          What is the dimension of <m>U</m>? (So what must be the dimension of its complement?)
          What condition ensures that a polynomial does not belong to <m>U</m>?
        </p>
      </hint>
      <solution>
        <p>
          Since <m>\dim U=3</m> and <m>\dim P_3(\R)=4</m>,
          we know that any complement of <m>U</m> must be one-dimensional.
        </p>
        <p>
          Therefore, a basis for a complement <m>W</m> of <m>U</m> is given by any polynomial in <m>P_3(\R)</m> that is not in <m>U</m>.
          In particular, we can choose any polynomial <m>p(x)</m> with <m>p(1)\neq 0</m>; for example, <m>p(x)=x</m>.
          Therefore, <m>W=\{ax\,|\, a\in\R\}</m> is a complement of <m>U</m>.
        </p>
      </solution>
    </task>
  </exercise>

  <exercise>
    <introduction>
      <p>
        Let <m>U</m> be the subspace of <m>\R^5</m> define by
        <me>
          U = \{(x_1,x_2,x_3,x_4,x_5)\,|\, x_1=3x_3, \text{ and } 3x_2-5x_4=x_5\}
        </me>.
      </p>
    </introduction>
    <task>
      <statement>
        <p>
          Determine a basis for <m>U</m>.
        </p>
      </statement>
      <hint>
        <p>
          Try plugging in the given conditions, and then decomposing the vector into pieces with one variable each.
        </p>
      </hint>
      <solution>
        <p>
          If <m>\uu\in U</m>, then
          <md>
            <mrow>\uu \amp = (3x_3,x_2,x_3,x_4,3x_2-5x_4)</mrow>
            <mrow> \amp = (0,x_2,0,0,3x_2)+(3x_3,0,x_3,0,0)+(0,0,0,x_4,-5x_4)</mrow>
            <mrow> \amp = x_2(0,1,0,0,3)+x_3(3,0,1,0,0)+x_4(0,0,0,1,-5)</mrow>
          </md>.
        </p>
        <p>
          This shows that <m>U=\spn \{(0,1,0,0,3), (3,0,1,0,0), (0,0,0,1,-5)\}</m>.
          These vectors are also linearly independent,
          since each one has its first leading (nonzero) entry in a different position.
          (Think about what this implies for the <init>RREF</init> of the resulting matrix.)
        </p>
      </solution>
    </task>
    <task>
      <statement>
        <p>
          Find a complement of <m>U</m>.
        </p>
      </statement>
      <hint>
        <p>
          One way to solve this is to ask yourself,
          what vectors are <em>not</em> in the span of the basis you found above?
          You can do this by solving an appropriate system of equations.
        </p>
      </hint>
      <solution>
        <p>
          Since <m>\dim U = 3</m>, any complement of <m>U</m> must have dimension 2.
          We therefore need to find two independent vectors that do not belong to <m>U</m>.
        </p>
        <p>
          Recall that <m>U</m> is defined by two conditions:
          <m>x_1=3x_3</m> and <m>3x_2-5x_4=x_5</m>.
          Therefore, a vector is <em>not</em> in <m>U</m> if <m>x_1\neq x_3</m>,
          <em>or</em> <m>x_5\neq 3x_2-5x_4</m>.
          This suggests that we define two vectors, each of which violates one of these conditions.
        </p>
        <p>
          For the first, let us take <m>\xx=(1,0,1,0,0)</m>.
          This is not in <m>U</m> because <m>1\neq 3(1)</m>.
          For the second, let us take <m>\yy=(0,1,0,1,1)</m>.
          This is not in <m>U</m> because <m>1\neq 3(1)-5(1)</m>.
          We know that <m>\{\xx,\yy\}</m> is linearly independent,
          because each vector has nonzero entries in different positions.
          Therefore, <m>W=\spn\{\xx,\yy\}</m> is a complement of <m>U</m>,
          since it is spanned by vectors not in <m>U</m>, and it has the correct dimension.
        </p>
      </solution>
    </task>
  </exercise>

  <exercise xml:id="ex-using-sum-dimension">
    <statement>
      <p>
        Suppose <m>U</m> and <m>W</m> are 4-dimensional subspaces of <m>\R^6</m>.
        What are all possible dimensions of <m>U\cap W</m>?
      </p>
    </statement>
    <choices randomize="yes">
      <choice correct="no">
        <statement>
          <p>
            <m>1</m>
          </p>
        </statement>
        <feedback>
          <p>
            What would <xref ref="thm-sum-dimension"/> say about <m>\dim U+W</m> in this case?
            Why is that not possible?
          </p>
        </feedback>
      </choice>
      <choice correct="yes">
        <statement>
          <p>
            <m>2</m>
          </p>
        </statement>
        <feedback>
          <p>
            Good job! If <m>\dim U+W = 6</m> (the largest it possibly can),
            then <m>\dim U\cap W = \dim U+\dim W-\dim (U+W) = 4+4-6=2</m>.
          </p>
        </feedback>
      </choice>
      <choice correct="yes">
        <statement>
          <p>
            <m>3</m>
          </p>
        </statement>
        <feedback>
          <p>
            Yes! This will be the case if <m>\dim U+W = 5</m>.
          </p>
        </feedback>
      </choice>
      <choice correct="yes">
        <statement>
          <p>
            <m>4</m>
          </p>
        </statement>
        <feedback>
          <p>
            Correct! If <m>U\subseteq W</m>, then <m>U=W=U+W=U\cap W</m>, all with dimension <m>4</m>.
          </p>
        </feedback>
      </choice>
      <choice correct="no">
        <statement>
          <p>
            <m>5</m>
          </p>
        </statement>
        <feedback>
          <p>
            Since <m>U+W</m> contains both <m>U</m> and <m>W</m>, its dimension cannot be less than <m>4</m>.
          </p>
        </feedback>
      </choice>
    </choices>
    <hint>
      <p>
        Use <xref ref="thm-sum-dimension"/>.
      </p>
    </hint>
  </exercise>
</section>
