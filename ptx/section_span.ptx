<?xml version="1.0" encoding="UTF-8" ?>

<section xml:id="sec-span">
  <title>Span</title>
  <p>
    Recall that a <term>linear combination</term> of a set of vectors
    <m>\vv_1,\ldots, \vv_k</m> is a vector expression of the form
    <me>
      \ww=c_1\vv_1+c_2\vv_2+\cdots +c_k\vv_k,
    </me>
    where <m>c_1,\ldots, c_k</m> are scalars.
  </p>

  <p>
    It's important to make sure you don't get lost in the notation here.
    Be sure that you can keep track of which symbols are vectors, and which are scalars!
    Note that in a sense, this is the most general sort of expression you can form using the two operations of a vector space,
    addition, and scalar multiplication. We multiply some collection of vectors by scalars,
    and then use addition to <q>combine</q> them into a single vector.
  </p>

  <example>
    <statement>
      <p>
        In <m>\R^3</m>, let <m>\uu = \bbm 1\\0\\3\ebm</m>, <m>\vv = \bbm -1\\2\\1\ebm</m>, and <m>\ww = \bbm 0\\3\\1\ebm</m>.
        With scalars <m>3,-2,4</m> we can form the linear combination
        <me>
          3\uu-2\vv+4\ww = \bbm 3\\0\\9\ebm+\bbm 2\\-4\\-2\ebm + \bbm 0\\12\\4\ebm = \bbm 5\\8\\11\ebm
        </me>.
        Notice how the end result is a single vector, and we've lost all information regarding the vectors it came from.
        Sometimes we want the end result, but often we are more interested in details of the linear combination itself.
      </p>

      <p>
        In the vector space of all real-valued continuous functions on <m>\R</m>,
        we can consider linear combinations such as <m>f(x)=3e^{2x}+4\sin(3x)-3\cos(3x)</m>.
        (This might, for example, be a particular solution to some differential equation.)
        Note that in this example, there is no nice way to <q>combine</q> these functions into a single term.
      </p>
    </statement>
  </example>

  <p>
    The <term>span</term> of those same vectors is the set of all possible linear combinations that can be formed:
  </p>

  <definition xml:id="def-span">
    <title>Span</title>
    <statement>
      <p>
        Let <m>\vv_1,\ldots, \vv_k</m> be a set of vectors in a vector space <m>V</m>.
        The <term>span</term> of this set of vectors is the subset of <m>V</m> defined by
        <me>
          \spn\{\vv_1,\ldots, \vv_k\} = \{c_1\vv_1+ \cdots + c_k\vv_k \,|\, c_1,\ldots, c_k \in \mathbb{F}\}
        </me>.
      </p>
    </statement>
  </definition>

  <p>
    The vectors <m>\vv_1,\ldots, \vv_k</m> can be thought of as the <term>generators</term> of the span.
    Every other vector in the set can be obtained as a linear combination of these vectors.
    Note that even though we have finitely many generators,
    because the set (usually <m>\R</m>) from which we choose our scalars is infinite,
    there are infinitely many elements in the span.
  </p>

  <p>
    Since span is defined in terms of linear combinations,
    what the question <q>Is the vector <m>\ww</m> in <m>\spn\{\vv_1,\ldots, \vv_k\}</m>?</q>
    is really asking is, <q>Can <m>\ww</m> be written as a linear combination of <m>\vv_1,\ldots, \vv_k</m>?</q>
  </p>

  <p>
    With the appropriate setup, all such questions become questions about solving systems of equations.
    Here, we will look at a few such examples.
  </p>

  <exercise>
    <statement>
      <p>
        Determine whether the vector <m>\bbm 2\\3\ebm</m> is in the span of the vectors <m>\bbm 1\\1\ebm,\bbm -1\\2\ebm</m>.
      </p>
    </statement>
    <solution>
      <p>
        This is really asking: are there scalars <m>s,t</m> such that
        <me>
          s\bbm 1\\1\ebm + t\bbm -1\\2\ebm = \bbm 2\\3\ebm
        </me>?
        And this, in turn, is equivalent to the system
        <md>
          <mrow>s -t \amp=2 </mrow>
          <mrow>s+2t \amp=3 </mrow>
        </md>,
        which is the same as the matrix equation
        <me>
          \bbm 1\amp -1\\1\amp 2\ebm\bbm s\\t\ebm = \bbm 2\\3\ebm.
        </me>
        Solving the system confirms that there is indeed a solution, so the answer to our original question is yes.
      </p>

      <p>
        To confirm the above example (and see what the solution is), we can use the computer.
        This first code cell loads the <c>sympy</c> Python library,
        and then configures the output to look nice.
        For details on the code used below, see <xref ref="ch-computation" text="custom">the Appendix</xref>.
      </p>

      <sage>
        <input>
          from sympy import Matrix, init_printing
          init_printing()
          A = Matrix(2,3,[1,-1,2,1,2,3])
          A.rref()
        </input>
        <output>
          \[\bbm 1\amp 0\amp \frac73\\0\amp 1\amp \frac13\ebm, (0,1)\]
        </output>
      </sage>

      <p>
        The above code produces the reduced row-echelon form of the augmented matrix for our system.
        (The tuple <m>(0,1)</m> lists the pivot columns <mdash/> note that Python indexes the columns starting at <m>0</m> rather than <m>1</m>.)
        Do you remember how to get the answer from here? Here's another approach.
      </p>

      <sage>
        <input>
          B = Matrix(2,2,[1,-1,1,2])
          B
        </input>
        <output>
          \[\bbm 1\amp -1\\1\amp 2\ebm\]
        </output>
      </sage>

      <sage>
        <input>
          C = Matrix(2,1,[2,3])
          X = (B**-1)*C
          X
        </input>
        <output>
          \[\bbm \frac 73\\\frac13\ebm\]
        </output>
      </sage>
    </solution>
  </exercise>

  <p>
    Our next example involves polynomials.
    At first this looks like a different problem,
    but it's essentially the same once we set it up.
  </p>

  <exercise>
    <statement>
      <p>
        Determine whether <m>p(x)=1+x+4x^2</m> belongs to
        <m>\spn\{1+2x-x^2,3+5x+2x^2\}</m>.
      </p>
    </statement>
    <solution>
      <p>
        We seek scalars <m>s,t</m> such that
        <me>
          s(1+2x-2x^2)+t(3+5x+2x^2)=1+x+4x^2
        </me>.
        On the left-hand side, we expand and gather terms:
        <me>
          (s+3t)+(2s+5t)x+(-2s+2t)x^2 = 1+x+4x^2
        </me>.
        These two polynomials are equal if and only if we can solve the system
        <md>
          <mrow>s+3t \amp = 1 </mrow>
          <mrow>2s+5t \amp =1</mrow>
          <mrow> -2s+2t \amp =4</mrow>
        </md>.
      </p>

      <p>
        We can solve this computationally using matrices again.
      </p>
      <sage>
        <input>
          from sympy import Matrix, init_printing
          init_printing()
          M = Matrix(3,3,[1,3,1,2,5,1,-2,2,4])
          M.rref()
        </input>
        <output>
          \[\bbm 1\amp 0\amp 0\\0\amp 1\amp 0\\0\amp 0\amp 1\ebm, (0,1,2)\]
        </output>
      </sage>
      <p>
        So, what's the answer? Is <m>p(x)</m> in the span?
        Can we determine what polynomials are in the span?
        Let's consider a general polynomial <m>q(x)=a+bx+cx^2</m>.
        A bit of thought tells us that the coefficients <m>a,b,c</m>
        should replace the constants <m>1,1,4</m> above.
      </p>

      <sage>
        <input>
          from sympy import symbols
          a, b, c = symbols('a b c', real = True, constant = True)
          N = Matrix(3,3,[1,3,a,2,5,b,-2,2,c])
          N
        </input>
        <output>
          \[\bbm 1\amp 3\amp a\\2\amp 5\amp b\\-2\amp 2\amp c\ebm\]
        </output>
      </sage>

      <p>
        Asking the computer to reduce this matrix to <init>RREF</init> won't produce the desired result.
        But we can always specify row operations.
      </p>

      <sage>
        <input>
          N1 = N.elementary_row_op(op='n-&gt;n+km',row=1,k=-2,row2=0)
          N1
        </input>
        <output>
          \[\bbm 1\amp 3\amp a\\0\amp -1\amp -2a+b\\-2\amp 2\amp c\ebm\]
        </output>
      </sage>

      <p>
        In the <c>elementary_row_op</c> function called above,
        we are asking the computer to change row <m>1</m> (the second row)
        by adding <m>-2</m> times row <m>0</m> )the first row).
        See <xref ref="subsec-sympy-matrix">Section</xref> for complete details on this syntax.
      </p>

      <p>
        Now we repeat. Here is another cell to work with:
      </p>

      <sage>

      </sage>

      <p>
        Another option is to replace the <c>rref()</c> function with the
        <c>echelon_form()</c> function, which doesn't simplify quite as far:
      </p>

      <sage>
        <input>
          a, b, c = symbols('a b c', real = True, constant = True)
          N = Matrix(3,3,[1,3,a,2,5,b,-2,2,c])
          N.echelon_form()
        </input>
        <output>
          \[\bbm 1\amp 3\amp a\\0\amp -1\amp -2a+b\\0\amp 0\amp 14a-8b-c\ebm\]
        </output>
      </sage>

      <p>
        For a consistent system, we need <m>c=14a-8b</m>.
      </p>
    </solution>
  </exercise>


  <p>
    One of the reasons we care about linear combinations and span is that it gives us an easy means of generating subspaces,
    as the following theorem suggests.
  </p>

  <theorem xml:id="thm-span-is-subspace">
    <statement>
      <p>
        Let <m>V</m> be a vector space, and let <m>\vv_1,\vv_2,\ldots, \vv_k</m> be vectors in <m>V</m>. Then:
        <ol>
          <li>
            <p>
              <m>U=\spn\{\vv_1,\vv_2,\ldots, \vv_k\}</m> is a subspace of <m>V</m>.
            </p>
          </li>

          <li>
            <p>
              <m>U</m> is the <em>smallest</em> subspace of  <m>V</m> containing <m>\vv_1,\ldots, \vv_k</m>,
              in the sense that if <m>W\subseteq V</m> is a subspace and <m>\vv_1,\ldots, \vv_k\in W</m>,
              then <m>U\subseteq W</m>.
            </p>
          </li>
        </ol>
      </p>
    </statement>
    <proof>
      <title>Strategy</title>
      <p>
        For the first part, we will rely on our trusty <xref ref="thm-subspace-test" text="title"/>.
        The proof is essentially the same as the motivating example from the beginning of <xref ref="sec-subspace"/>,
        modified to allow an arbitrary number of vectors.
        First, we will write the zero vector as a linear combination of the given vectors. (What should the scalars be?)
        Then we check addition and scalar multiplication.
      </p>

      <p>
        How do we show that a subspace is <em>smallest</em>?
        As suggested in the statement above, show that if a subspace <m>W</m>
        contains the vectors <m>\vv_1,\vv_2,\ldots, \vv_k</m>,
        then it must contain every vector in <m>U</m>.
        This must be the case because <m>W</m> is closed under addition and scalar multiplication,
        and every vector in <m>U</m> is formed using these operations.
      </p>
    </proof>

    <proof>

      <p>
        Let <m>U=\spn\{\vv_1,\vv_2,\ldots, \vv_k\}</m>. Then <m>0\in U</m>,
        since <m>0=0\vv_1+0\vv_2+\cdots + 0\vv_k</m>.
        If <m>\uu=a_1\vv_1+a_2\vv_2+\cdots +a_k\vv_k</m> and <m>\ww=b_1\vv_1+b_2\vv_2+\cdots +b_k\vv_k</m>
        are vectors in <m>U</m>, then
        <md>
          <mrow>\uu+\ww \amp =(a_1\vv_1+a_2\vv_2+\cdots +a_k\vv_k)+(b_1\vv_1+b_2\vv_2+\cdots +b_k\vv_k)</mrow>
          <mrow> \amp = (a_1+b_1)\vv_1+(a_2+b_2)\vv_2+\cdots + (a_k+b_k)\vv_k</mrow>
        </md>
        is in <m>U</m>, and
        <md>
          <mrow>c\uu \amp =c(a_1\vv_1+a_2\vv_2+\cdots +a_k\vv_k)</mrow>
          <mrow> \amp =(ca_1)\vv_1+(ca_2)\vv_2+\cdots + (ca_k)\vv_k</mrow>
        </md>
        is in <m>U</m>, so by <xref ref="thm-subspace-test">Theorem</xref>,
        <m>U</m> is a subspace.
      </p>

      <p>
        To see that <m>U</m> is the smallest subspace containing <m>\vv_1,\ldots, \vv_k</m>,
        we need only note that if <m>\vv_1,\ldots, \vv_k\in W</m>,
        where <m>W</m> is a subspace, then since <m>W</m> is closed under scalar multiplication,
        we know that <m>c_1\vv_1,\ldots, c_k\vv_k</m> for any scalars <m>c_1,\ldots, c_k</m>,
        and since <m>W</m> is closed under addition, <m>c_1\vv_1+\cdots+c_k\vv_k\in W</m>.
        Thus, <m>W</m> contains all linear combinations of <m>\vv_1,\ldots, \vv_k</m>,
        which is to say that <m>W</m> contains <m>U</m>.
      </p>
    </proof>

  </theorem>

  <exercise>
    <statement>
      <p>
        Let <m>V</m> be a vector space, and let <m>X,Y\subseteq V</m>.
        Show that if <m>X\subseteq Y</m>, then <m>\spn X \subseteq \spn Y</m>.
      </p>
    </statement>
    <hint>
      <p>
        Your goal is to show that any linear combination of vectors in <m>X</m>
        can also be written as a linear combination of vectors in <m>Y</m>.
        What value should you choose for the scalars in front of any vectors that belong to <m>Y</m> but not <m>X</m>?
      </p>
    </hint>
  </exercise>

  <exercise>
    <statement correct="no">
      <p>
        The vectors <m>\{(1,2,0), (1,1,1)\}</m> span <m>\{(a,b,0)\,|\, a,b \in\R\}</m>.
      </p>
    </statement>
    <feedback>
      <p>
        The only way to get <m>0</m> as the third component of <m>s(1,2,0)+t(1,1,1)</m> is to set <m>t=0</m>.
        But the scalar multiples of <m>(1,2,0)</m> do not generate all vectors of the form <m>(a,b,0)</m>.
      </p>
    </feedback>
  </exercise>

  <p>
    We end with a result that will be important as we work on our understanding of the structure of vector spaces.
  </p>

  <theorem xml:id="theorem-surplus-span">
    <statement>
      <p>
        Let <m>V</m> be a vector space, and let <m>\vv_1,\ldots, \vv_k\in V</m>.
        If <m>\uu\in \spn\{\vv_1,\ldots, \vv_k\}</m>, then
        <me>
          \spn\{\uu,\vv_1,\ldots, \vv_k\} = \spn\{\vv_1,\ldots, \vv_k\}
        </me>.
      </p>
    </statement>
    <proof>
      <title>Strategy</title>
      <p>
        We need to first recall that the span of a set of vectors is, first and foremost, a set.
        That means that we are proving the equality of two sets.
        Recall that this typically requires us to prove that each set is a subset of the other.
      </p>

      <p>
        This means that we need to show that any linear combination of the vectors
        <m>\uu,\vv_1,\ldots, \vv_k</m> can be written as a linear combination of the vectors
        <m>\vv_1,\ldots, \vv_k</m>, and vice-versa.
        In one direction, we will need our hypothesis: <m>\uu\in \spn\{\vv_1,\ldots, \vv_k\}</m>.
        In the other direction, we come back to a trick we've already seen: adding zero does nothing.
        That is, if a vector is missing from a linear combination, we can include it, using <m>0</m> for its coefficient.
      </p>
    </proof>
    <proof>

      <p>
        Suppose that <m>\uu\in \spn\{\vv_1,\ldots, \vv_k\}</m>.
        This means that <m>\uu</m> can be written as a linear combination of the vectors <m>\vv_1,\ldots, \vv_k</m>,
        so there must exist scalars <m>a_1,\ldots, a_k</m> such that
        <men xml:id="eq-u-in-span">
          \uu=a_1\vv_1+a_2\vv_2+\cdots _a_k\vv_k
        </men>.
        Now, let <m>\ww\in \uu\in \spn\{\uu,\vv_1,\ldots, \vv_k\}</m>.
        Then we must have
        <me>
          \ww = b\uu+c_1\vv_1+\cdots+c_k\vv_k
        </me>
        for scalars <m>b,c_1,\ldots, c_k</m>. From our hypothesis (using <xref ref="eq-u-in-span"/>), we get
        <md>
          <mrow>\ww \amp = b(a_1\vv_1+a_2\vv_2+\cdots _a_k\vv_k) +c_1\vv_1+\cdots +\c_k\vv_k</mrow>
          <mrow> \amp = ((ba_1)\vv_1+\cdots + (ba_k)\vv_k)+(c_1\vv_1+\cdots +\c_k\vv_k)</mrow>
          <mrow> \amp = (ba_1+c_1)\vv_1+\cdots+(ba_k+c_k)\vv_k</mrow>
        </md>.
        Since <m>\ww</m> can be written as a linear combination of <m>\vv_1,\ldots, \vv_k</m>,
        <m>\ww\in\spn\{\vv_1,\ldots, \vv_k\}</m>, and therefore <m>\spn\{\uu,\vv_1,\ldots, \vv_k\}\subseteq \spn\{\vv_1,\ldots, \vv_k\}</m>.
      </p>
      <p>
        On the other hand, let <m>\xx\in \spn\{\vv_1,\ldots, \vv_k\}</m>.
        Then there exist scalars <m>c_1,\ldots, c_k</m> for which we have
        <md>
          <mrow>\xx \amp = c_1\vv_1+\cdots +c_k\vv_k</mrow>
          <mrow> \amp = 0\uu + c_1\vv_1+\cdots + c_k\vv_k</mrow>
        </md>.
        Therefore, <m>\xx\in\spn\{\uu,\vv_1,\ldots, \vv_k\}</m>,
        which proves the opposite conclusion, and therefore the result.
      </p>
    </proof>
  </theorem>

  <p>
    The moral of <xref ref="theorem-surplus-span">Theorem</xref>
    is that one vector in a set is a linear combination of the others,
    we can remove it from the set without affecting the span.
    This suggests that we might want to look for the most <q>efficient</q>
    spanning sets <ndash /> those in which no vector in the set can be written in terms of the others.
    Such sets are called <term>linearly independent</term>,
    and they are the subject of <xref ref="sec-independence">Section</xref>.
  </p>
</section>
