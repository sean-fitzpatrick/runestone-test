<?xml version="1.0" encoding="UTF-8" ?>

<section xml:id="sec-vec-sp">
  <title>Definition and examples</title>

  <p>
    Let's recall what we know about vectors in <m>\R^2</m>.
    Writing <m>\vv = \langle x,y\rangle</m> for the vector pointing from <m>(0,0)</m> to <m>(x,y)</m>,
    we define:
    <ol>
      <li>
        <p>
          Addition: <m>\langle x_1,y_1\rangle + \langle x_2,y_2\rangle = \langle x_1+y_1, x_2+y_2\rangle</m>
        </p>
      </li>
      <li>
        <p>
          Scalar multiplication: <m>c\langle x, y\rangle = \langle cx, cy\rangle</m>,
          where <m>c</m> is a real number, or <em>scalar</em>.
        </p>
      </li>
    </ol>
  </p>

  <p>
    We can then observe a number of properties enjoyed by these operations.
    In your first course, you may have observed some of these properties geometrically,
    using the <q>tip-to-tail</q> rule for vector addition.
  </p>

  <p>
    <ol>
      <li>
        <p>
          Vector addition is <em>commutative</em>.
          That is, for any vectors <m>\vv = \langle a, b\rangle</m> and <m>\ww = \langle c,d\rangle</m>,
          we have <m>\vv+\ww = \ww+\vv</m>.
        </p>
        <p>
          This is true because addition is commutative for the real numbers:
          <me>
            \vv+\ww = \langle a+c, b+d\rangle = \langle c+a, d+b\rangle = \ww+\vv
          </me>.
        </p>
      </li>

      <li>
        <p>
          Vector addition is <em>associative</em>.
          That is, for any vectors <m>\uu = \langle a, b\rangle, \vv = \langle c, d\rangle</m>
          and <m>\ww = \langle p, q\rangle</m>, we have
          <me>
            \uu+(\vv+\ww) = (\uu+\vv)+\ww
          </me>.
          This tells us that placement of parentheses doesn't matter,
          which is essential for extending addition (which is defined as an operation on <em>two</em> vectors)
          to sums of three or more vectors.
        </p>
        <p>
          Again, this property is true because it is true for real numbers:
          <md>
            <mrow>\uu + (\vv+\ww) \amp = \langle a,b\rangle + \langle c+p,d+q\rangle </mrow>
            <mrow> \amp = \langle a+(c+p), b+(d+q)\rangle</mrow>
            <mrow> \amp = \langle (a+c)+p, (b+d)+q\rangle</mrow>
            <mrow> \amp = \langle a+c, b+d\rangle + \langle p,q\rangle</mrow>
            <mrow> \amp = (\uu+\vv)+\ww</mrow>
          </md>.
        </p>
      </li>
      <li>
        <p>
          Vector addition has an <em>identity element</em>.
          This is a vector that has no effect when added to another vector,
          or in other words, the zero vector.
          Again, it inherits its property from the behaviour of the real number 0.
        </p>
        <p>
          For any <m>\vv=\langle a,b\rangle</m>, the vector <m>\zer = \langle 0,0\rangle</m>
          satisfies <m>\vv+\zer = \zer+\vv=\vv</m>:
          <me>
            \langle a+0,b+0\rangle = \langle 0+a,0+b\rangle = \langle a,b\rangle
          </me>.
        </p>
      </li>
      <li>
        <p>
          Every vector has an <em>inverse</em> with respect to addition,
          or, in other words, a <em>negative</em>.
          Given a vector <m>\vv = \langle a, b\rangle</m>,
          the vector <m>-\vv = \langle -a, -b\rangle</m> satisfies
          <me>
            \vv+(-\vv) = -\vv + \vv = \zer
          </me>.
          (We will leave this one for you to check.)
        </p>
      </li>
      <li>
        <p>
          Scalar multiplication is compatible with addition in two different ways.
          First, it is <em>distributive</em> over vector addition:
          for any scalar <m>k</m> and vectors <m>\vv=\langle a, b\rangle, \ww = \langle c,d\rangle</m>,
          we have <m>k(\vv+\ww)=k\vv+k\ww</m>.
        </p>

        <p>
          Unsurprisingly, this property is inherited from the distributive property of the real numbers:
          <md>
            <mrow>k(\vv+ww) \amp = k\langle a+c,b+d\rangle</mrow>
            <mrow> \amp = \langle k(a+c),k(b+d)\rangle </mrow>
            <mrow> \amp = \langle ka+kc,kb+kd\rangle</mrow>
            <mrow> \amp = \langle ka, kb\rangle+\langle kc, kd\rangle</mrow>
            <mrow> \amp k\langle a,b\rangle + k\langle c,d\rangle = k\vv+k\ww</mrow>
          </md>.
        </p>
      </li>
      <li>
        <p>
          Second, scalar multiplication is also distributive with respect to <em>scalar</em>
          addition: for any scalars <m>c</m> and <m>d</m> and vector <m>\vv</m>,
          we have <m>(c+d)\vv=c\vv+d\vv</m>.
        </p>
        <p>
          Again, this is because real number addition is distributive:
          <md>
            <mrow>(c+d)\langle a, b\rangle \amp = \langle (c+d)a,(c+d)b\rangle</mrow>
            <mrow> \amp = \langle ca+da, cb+db\rangle </mrow>
            <mrow> \amp = \langle ca, cb\rangle + \langle da, db\rangle</mrow>
            <mrow> \amp c\langle a, b\rangle + d\langle a, b\rangle</mrow>
          </md>.
        </p>
      </li>
      <li>
        <p>
          Scalar multiplication is also <em>associative</em>.
          Given scalars <m>c,d</m> and a vector <m>\vv=\langle a,b\rangle</m>,
          we have <m>c(d\vv) = (cd)\vv</m>.
        </p>
        <p>
          This is inherited from the associativity of real number multiplication:
          <me>
            c(d\vv) = c\langle da, db\rangle =\langle c(da),c(db)\rangle = \langle (cd)a,(cd)b\rangle = (cd)\langle a,b\rangle
          </me>.
        </p>
      </li>

      <li>
        <p>
          Finally, there is a <q>normalization</q> result for scalar multiplication.
          For any vector <m>\vv</m>, we have <m>1\vv = \vv</m>.
          That is, the real number <m>1</m> acts as an identity element with respect to scalar multiplication.
          (You can check this one yourself.)
        </p>
      </li>
    </ol>
  </p>

  <p>
    You might be wondering why we bother to list the last property above.
    It's true, but why do we need it?
    One reason comes from basic algebra, and solving equations.
    Suppose we have the equation <m>c\vv = \ww</m>, where <m>c</m> is some nonzero scalar,
    and we want to solve for <m>\vv</m>.
    Very early in our algebra careers, we learn that to solve, we <q>divide by <m>c</m></q>.
  </p>

  <p>
    Division doesn't quite make sense in this context,
    but it certainly does make sense to multiply both sides by <m>1/c</m>,
    the multiplicative inverse of <m>c</m>.
    We then have <m>(1/c)(c\vv)=(1/c)\ww</m>, and since scalar multiplication is associative,
    <m>(1/c\cdot c)\vv = (1/c)\ww</m>.
    We know that <m>1/c \cdot c = 1</m>, so this boils down to <m>1\vv=(1/c)\ww</m>.
    It appears that we've solved the equation, but <em>only if we know</em> that <m>1\vv = \vv</m>.
  </p>

  <p>
    For an example where this fails, take our vectors as above,
    but redefine the scalar multiplication as <m>c\langle a, b\rangle = \langle ca, 0\rangle</m>.
    The distributive and associative properties for scalar multiplication will still hold,
    but the normalization property fails.
    Algebra becomes very strange with this version of scalar multiplication.
    In particular, we can no longer conclude that if <m>2\vv=2\ww</m>, then <m>\vv=\ww</m>!
  </p>

  <p>
    In a first course in linear algebra,
    these algebraic properties of vector addition and scalar multiplication are presented as a <em>theorem</em>.
    (After all, we have just demonstrated the truth of these results.)
    A second course in linear algebra (and in particular, <em>abstract</em> linear algebra),
    begins by taking that theorem and turning it into a <em>definition</em>.
    We will then do some exploration, to see if we can come up with some other examples that fit the definition;
    the significance of this is that we can expect the algebra in these examples
    to behave in essentially the same way as the vectors we're familiar with.
  </p>

  <definition xml:id="def-vector-space">
    <statement>
      <p>
        A <term>real vector space</term> (or vector space over <m>\R</m>) is a nonempty set <m>V</m>, whose objects are called <term>vectors</term>,
        equipped with two operations:
        <ol>
          <li>
            <p>
              <term>Addition</term>, which is a map from <m>V\times V</m> to <m>V</m>
              that associates each ordered pair of vectors <m>(\vv,\ww)</m> to a vector <m>\vv+\ww</m>,
              called the <term>sum</term> of <m>\vv</m> and <m>\ww</m>.
            </p>
          </li>

          <li>
            <p>
              <term>Scalar multiplication</term>, which is a map from <m>\R\times V</m> to <m>V</m>
              that associates each real number <m>c</m> and vector <m>\vv</m> to a vector <m>c\vv</m>.
            </p>
          </li>
        </ol>
      </p>

      <p>
        The operations of addition and scalar multiplication are required to satisfy the following <em>axioms</em>:
        <dl>
          <li>
            <title>A1.</title>
            <p>
              If <m>\uu,\vv\in V</m>, then <m>\uu+\vv\in V</m>. (Closure under addition)
            </p>
          </li>
          <li>
            <title>A2.</title>
            <p>
              For all <m>\uu,\vv\in V</m>, <m>\uu+\vv=\vv+\uu</m>. (Commutativity of addition)
            </p>
          </li>
          <li>
            <title>A3.</title>
            <p>
              For all <m>\uu,\vv,\ww\in V</m>, <m>\uu+(\vv+\ww)=(\uu+\vv)+\ww</m>. (Associativity of addition)
            </p>
          </li>
          <li>
            <title>A4.</title>
            <p>
              There exists an element <m>\zer\in V</m> such that <m>\vv+\zer=\vv</m> for each <m>\vv\in V</m>. (Existence of a zero vector)
            </p>
          </li>
          <li>
            <title>A5.</title>
            <p>
              For each <m>\vv\in V</m>, there exists a vector <m>-\vv\in V</m> such that <m>\vv+(-\vv)=\zer</m>. (Existence of negatives)
            </p>
          </li>
          <li>
            <title>S1.</title>
            <p>
              If <m>\vv\in V</m>, then <m>c\vv\in V</m> for all <m>c\in\R</m>. (Closure under scalar multiplication)
            </p>
          </li>
          <li>
            <title>S2.</title>
            <p>
              For all <m>c\in \R</m> and <m>\vv,\ww\in V</m>, <m>c(\vv+\ww)=c\vv+c\ww</m>. (Distribution over vector addition)
            </p>
          </li>
          <li>
            <title>S3.</title>
            <p>
              For all <m>a,b\in\R</m> and <m>\vv\in V</m>, <m>(a+b)\vv=a\vv+b\vv</m>. (Distribution over scalar addition)
            </p>
          </li>
          <li>
            <title>S4.</title>
            <p>
              For all <m>a,b\in \R</m> and <m>\vv\in V</m>, <m>a(b\vv)=(ab)\vv</m>. (Associativity of scalar multiplication)
            </p>
          </li>
          <li>
            <title>S5.</title>
            <p>
              For all <m>\vv\in V</m>, <m>1\vv=\vv</m>. (Normalization of scalar multiplication)
            </p>
          </li>
        </dl>
      </p>
    </statement>
  </definition>

  <p>
    Note that a zero vector must exist in every vector space.
    This simple observation is a key component of many proofs and counterexamples in linear algebra.
    In general, we may define a vector space whose scalars belong to a <em>field</em> <m>\mathbb{F}</m>.
    A field is a set of objects whose algebraic properties are modelled after those of the real numbers.
  </p>

  <p>
    The axioms for a field are not all that different than those for a vector space.
    The main difference is that in a field, multiplication is defined between elements of the field
    (and produces another element of the field),
    while scalar multiplication combines elements of two different sets.
  </p>

  <definition xml:id="def-field">
    <statement>
      <p>
        A <term>field</term> is a set <m>\mathbb{F}</m>,
        equipped with two binary operations <m>\mathbb{F}\times\mathbb{F} \to \mathbb{F}</m>:
        <md>
          <mrow> (a,b)\amp \mapsto a+b \quad \text{ usually called <term>addition</term>}</mrow>
          <mrow> (a,b)\amp \mapsto a\cdot b \text{ usually called <term>multiplication</term>}</mrow>
        </md>,
        such that the following axioms are satisfied:
        <ol>
          <li>
            <p>
              A1: for all <m>a,b\in \mathbb{F}, a+b=b+a</m>.
            </p>
          </li>
          <li>
            <p>
              A2: for all <m>a,b,c\in\mathbb{F}, a+(b+c)=(a+b)+c</m>
            </p>
          </li>
          <li>
            <p>
              A3: there exists an element <m>0\in\mathbb{F}</m> such that <m>0+a=a</m> for all <m>a\in\mathbb{F}</m>.
            </p>
          </li>
          <li>
            <p>
              A4: for each <m>a\in\mathbb{F}</m>, there exists an element <m>-a\in\mathbb{F}</m> such that <m>-a+a=0</m>.
            </p>
          </li>
          <li>
            <p>
              M1: for all <m>a,b\in\mathbb{F}</m>, <m>a\cdot b=b\cdot a</m>.
            </p>
          </li>
          <li>
            <p>
              M2: for all <m>a,b,c\in\mathbb{F}</m>, <m>a\cdot (b\cdot c)=(a\cdot b)\cdot c</m>.
            </p>
          </li>
          <li>
            <p>
              M3: there exists an element <m>1\in\mathbb{F}</m> such that <m>1\cdot a=a</m> for all <m>a\in \mathbb{F}</m>.
            </p>
          </li>
          <li>
            <p>
              M4: for each <m>a\in\mathbb{F}</m> with <m>a\neq 0</m>, there exists an element <m>1/a\in\mathbb{F}</m> such that <m>1/a\cdot a = 1</m>.
            </p>
          </li>
          <li>
            <p>
              D: for all <m>a,b,c\in \mathbb{F}</m>, <m>a\cdot (b+c) = a\cdot b+a\cdot c</m>.
            </p>
          </li>
        </ol>
      </p>
    </statement>
  </definition>

  <p>
    Note how the axioms for multiplication in a field mirror the addition axioms much more closely than in a vector space.
    The only difference is the fact that there is one element without a multiplicative inverse; namely, the zero element.
  </p>

  <p>
    While it is possible to study linear algebra over <em>finite fields</em> (like the integers modulo a prime number)
    we will only consider two fields: the real numbers <m>\R</m>, and the complex numbers <m>\C</m>.
  </p>

  <p>
    A vector space whose scalars are complex numbers will be called a <em>complex vector space</em>.
    While many students are initially intimidated by the complex numbers,
    most results in linear algebra work exactly the same over <m>\C</m> as they do over <m>\R</m>.
    And where the results differ, things are usually <em>easier</em> with complex numbers,
    owing in part to the fact that all complex polynomials can be completely factored.
  </p>

  <p>
    To help us gain familiarity with the abstract nature of <xref ref="def-vector-space"/>,
    let us consider some basic examples.
  </p>

  <example xml:id="ex-vector-spaces">
    <statement>
      <p>
        The following are examples of vector spaces. We leave verification of axioms as an exercise.
        (Verification will follow a process very similar to the discussion at the beginning of this section.)
        <ol>
          <li>
            <p>
              The set <m>\R^n</m> of <m>n</m>-tuples <m>(x_1,x_2,\ldots, x_n)</m> of real numbers,
              where we define
              <md>
                <mrow>(x_1,x_2,\ldots, x_n)+(y_1,y_2,\ldots, y_n) \amp = (x_1+y_1,x_2+y_2,\ldots, x_n+y_n) </mrow>
                <mrow> c(x_1,x_2,\ldots, x_n)\amp = (cx_1,cx_2,\ldots, cx_n)</mrow>
              </md>.
              We will also often use <m>\R^n</m> to refer to the vector space of <m>1\times n</m> column matrices <m>\bbm x_1\\x_2\\\vdots\\x_n\ebm</m>,
              where addition and scalar multiplication are defined as for matrices
              (and the same as the above, with the only difference being the way in which we choose to write our vectors).
              If the distinction between <m>n</m>-tuples and column matrices is ever important, it will be made clear.
            </p>
          </li>

          <li>
            <p>
              The set <m>M_{mn}(\R)</m> of <m>m\times n</m> matrices, equipped with the usual matrix addition and scalar multiplication.
            </p>
          </li>

          <li>
            <p>
              The set <m>P_n(\R)</m> of all polynomials
              <me>
                p(x) = a_0+a_1x+\cdots + a_nx^n
              </me>
              of degree less than or equal to <m>n</m>, where, for
              <md>
                <mrow>p(x) \amp = a_0+a_1x+\cdots + a_nx^n </mrow>
                <mrow>q(x) \amp = b_0+b_1x+\cdots +b_nx^n</mrow>
              </md>
              we define
              <me>
                p(x)+q(x)=(a_0+b_0)+(a_1+b_1)x+\cdots + (a_n+b_n)x^n
              </me>
              and
              <me>
                cp(x) = ca_0+(ca_1)x+\cdots + (ca_n)x^n
              </me>.
              The zero vector is the polynomial <m>0=0+0x+\cdots + 0x^n</m>.
            </p>

            <p>
              This is the same as the addition and scalar multiplication we get for functions in general,
              using the <q>pointwise evaluation</q> definition:
              for polynomials <m>p</m> and <m>q</m> and a scalar <m>c</m>,
              we have <m>(p+q)(x)=p(x)+q(x)</m> and <m>(cp)(x)=c\cdot p(x)</m>.
            </p>

            <p>
              Notice that although this feels like a very different example,
              the vector space <m>P_n(\R)</m> is in fact very similar to <m>\R^n</m>
              (or rather, <m>\R^{n+1}</m>, to be precise).
              If we associate the polynomial <m>a_0+a_1x+\cdots + a_nx^n</m>
              with the vector <m>\langle a_0,a_1,\ldots, a_n\rangle</m>,
              the addition and scalar multiplication for either space behaves in exactly the same way.
              We will make this observation precise in <xref ref="sec-isomorphism"/>.
            </p>
          </li>

          <li>
            <p>
              The set <m>P(\R)</m> of all polynomials of <em>any</em> degree.
              The algebra works the same as it does in <m>P_n(\R)</m>,
              but there is an important difference:
              in both <m>P_n(\R)</m> and <m>\R^n</m>,
              every element in the set can be generated by setting values for a finite collection of coefficients.
              (In <m>P_n(\R)</m>, every polynomial <m>a_0+a_1x+\cdots =a_nx^n</m>
              can be obtained by choosing values for the <m>n+1</m> coefficients <m>a_0,a_1\ldots, a_n</m>.)
              But if we remove the restriction on the degree of our polynomials,
              there is then no limit on the number of coefficients we might need.
              (Even if any <em>individual</em> polynomial has a finite number of coefficients!)
            </p>
          </li>

          <li>
            <p>
              The set <m>F[a,b]</m> of all functions <m>f:[a,b]\to \R</m>,
              where we define <m>(f+g)(x)=f(x)+g(x)</m> and <m>(cf)(x)=c(f(x))</m>.
              The zero function is the function satisfying <m>0(x)=0</m> for all <m>x\in [a,b]</m>,
              and the negative of a function <m>f</m> is given by <m>(-f)(x)=-f(x)</m> for all <m>x\in [a,b]</m>.
            </p>

            <p>
              Note that while the vector space <m>P(\R)</m> has an infinite nature that <m>P_n(\R)</m> does not,
              the vector space <m>F[a,b]</m> is somehow <em>more</em> infinite!
              Using the language of <xref ref="sec-dimension"/>, we can say that <m>P_n(\R)</m> is <term>finite dimensional</term>,
              while <m>P(\R)</m> and <m>F[a,b]</m> are <term>infinite dimensional</term>.
              In a more advanced course, one might make a further distinction:
              the dimension of <m>P(\R)</m> is countably infinite,
              while the dimension of <m>F[a,b]</m> is <term>uncountable</term>.
            </p>
          </li>
        </ol>
      </p>
    </statement>
  </example>

  <p>
    Other common examples of vector spaces can be found online;
    for example, <url href="https://en.wikipedia.org/wiki/Examples_of_vector_spaces" visual="en.wikipedia.org/wiki/Examples_of_vector_spaces">on Wikipedia</url>.
    It is also interesting to try to think of less common examples.
  </p>

  <exercise xml:id="ex-positive-reals-vecsp">
    <introduction>
      Can you think of a way to define a vector space structure on the set
      <m>(0,\infty)</m> of all positive real numbers?
    </introduction>
    <task>
      <statement>
        <p>
          How should we define addition and scalar multiplication?
        </p>
      </statement>
      <hint>
        <p>
          Note that the function <m>f(x)=e^x</m> has domain <m>(-\infty, \infty)</m>
          and range <m>(0,\infty)</m>. What does it do to a sum? To a product?
        </p>
      </hint>
      <solution>
        <p>
          To get a vector space structure on <m>V=(0,\infty)</m>,
          we will define an addition <m>\oplus</m> on <m>V</m> by
          <me>
            x\oplus y = xy
          </me>,
          where the right hand side is the usual product of real numbers,
          and for <m>c\in\R</m> and <m>x\in V</m>, we will define a scalar multiplication <m>\odot</m> by
          <me>
            c\odot x = x^c
          </me>.
        </p>
      </solution>
    </task>
    <task>
      <statement>
        <p>
          Show that the addition you defined satisfies the commutative and associative properties.
        </p>
      </statement>
      <hint>
        <p>
          You can assume that these properties are true for real number multiplication.
        </p>
      </hint>
      <solution>
        <p>
          For any <m>x,y,z\in V</m>, we have:
          <md>
            <mrow>x\oplus y \amp = xy = yx = y\oplus x</mrow>
            <mrow>x\oplus(y\oplus z)\amp = x\oplus yz = x(yz) = (xy)z = xy\oplus z = (x\oplus y)\oplus z</mrow>
          </md>.
        </p>
      </solution>
    </task>
    <task>
      <statement>
        <p>
          Which of the following is the identity element in <m>V</m>?
        </p>
      </statement>
      <choices randomize="yes">
        <choice>
          <statement>
            <p>
              <m>0</m>
            </p>
          </statement>
          <feedback>
            <p>
              Remember that the identity needs to be an element of the set!
            </p>
          </feedback>
        </choice>
        <choice correct="yes">
          <statement>
            <p>
              <m>1</m>
            </p>
          </statement>
          <feedback>
            <p>
              Correct! Since nothing happens when we multiply by 1, we get <m>1\oplus x=x</m> for any <m>x\in V</m>.
            </p>
          </feedback>
        </choice>
      </choices>
      <hint>
        <p>
          Remember that an identity element <m>e</m> must satisfy <m>e\oplus x</m> for any <m>x\in V</m>.
        </p>
      </hint>
    </task>
    <task>
      <statement>
        <p>
          What is the inverse of an element <m>x\in V</m>?
        </p>
      </statement>
      <hint>
        <p>
          Remember that an inverse <m>-x</m> must satisfy <m>x\oplus (-x)=e</m>,
          where <m>e</m> is the identity element. What is <m>e</m>, and how is <q>addition</q> defined?
        </p>
      </hint>
      <solution>
        <p>
          Let <m>x</m> be any element fo <m>V</m>. Since <m>x\gt 0</m>,
          we know in particular that <m>x\neq 0</m>, so we can define <m>-x = 1/x</m>,
          where <m>1/x</m> denotes the usual reciprocal of a real number.
          We then have
          <me>
            x\oplus (-x) = x(1/x) = 1
          </me>,
          and we saw above that <m>1</m> is the identity element of <m>e</m>.
        </p>
      </solution>
    </task>
    <task>
      <statement>
        <p>
          Show that, for any <m>c\in \R</m> and <m>x,y\in V</m>,
          <me>
            c\odot(x\oplus y) = c\odot x\oplus c\odot y
          </me>.
        </p>
      </statement>
      <solution>
        <p>
          We assume some properties of exponents from high school algebra:
          <me>
            c\odot(x\oplus y) = (xy)^c = x^c y^c = c\odot x \oplus c\odot y
          </me>.
        </p>
      </solution>
    </task>
    <task>
      <statement>
        <p>
          Show that for any <m>c,d\in \R</m> and <m>x\in V</m>,
          <me>
            (c+d)\odot x = c\odot x\oplus d\odot x
          </me>.
        </p>
      </statement>
      <solution>
        <p>
          This again follows from properties of exponents:
          <me>
            (c+d)\odot x = x^{c+d} = x^c x^d = c\odot x\oplus d\odot x
          </me>.
        </p>
      </solution>
    </task>
    <task>
      <statement>
        <p>
          Show that for any <m>c,d\in\R</m> and <m>x\in V</m>, <m>c\odot (d\odot x)=(cd)\odot x</m>.
        </p>
      </statement>
      <solution>
        <p>
          We have
          <me>
            c\odot (d\odot x) = c\odot (x^d) = (x^d)^c = x^{dc} = x^{cd} = (cd)\odot x
          </me>.
        </p>
      </solution>
    </task>
    <task>
      <statement>
        <p>
          Show that <m>1\odot x=x</m> for any <m>x\in V</m>.
        </p>
      </statement>
      <solution>
        <p>
          The last one is possibly the easiest: <m>1\odot x = x^1 = x</m>.
        </p>
      </solution>
    </task>
  </exercise>

  <exercise>
    <statement correct="yes">
      <p>
        The set of all polynomials with real number coefficients and degree less than or equal to three is a vector space,
        using the usual polynomial addition and scalar multiplication.
      </p>
    </statement>
    <feedback>
      <p>
        This is the vector space <m>P_3(\R)</m> from <xref ref="ex-vector-spaces"/>.
      </p>
    </feedback>
  </exercise>

  <exercise>
    <statement correct="no">
      <p>
        The set of all polynomials with real number coefficients and degree greater than or equal to three,
        together with the zero polynomial, is a vector space, using the usual polynomial addition and scalar multiplication.
      </p>
    </statement>
    <feedback>
      <p>
        The set is not closed under addition. What happens if you add the polynomials
        <m>x^3+x</m> and <m>-x^3+x</m>?
      </p>
    </feedback>
    <hint>
      <p>
        Remember that a vector space must be closed under the operations of addition and scalar multiplication.
      </p>
    </hint>
  </exercise>

  <exercise>
    <statement correct="no">
      <p>
        The set of all vectors <m>\vv = \langle a, b\rangle</m> of unit length
        (that is, such that <m>\sqrt{a^2+b^2}=1</m>) is a vector space
        with respect to the usual addition and scalar multiplication in <m>\R^2</m>.
      </p>
    </statement>
    <feedback>
      <p>
        The zero vector does not have unit length.
        Also, the sum of two unit vectors will usually not be a unit vector.
      </p>
    </feedback>
    <solution>
      <p>

      </p>
    </solution>
  </exercise>  
</section>
