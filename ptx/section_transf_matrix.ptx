<?xml version="1.0" encoding="UTF-8" ?>

<section xml:id="sec-matrix-of-transformation">
  <title>The matrix of a linear transformation</title>
  <p>
    Recall from <xref ref="ex-matrix-trans">Example</xref> in <xref ref="ch-linear-trans">Chapter</xref>
    that given any <m>m\times n</m> matrix <m>A</m>, we can define the matrix transformation
    <m>T_A:\R^n\to \R^m</m> by <m>T_A(\xx)=A\xx</m>,
    where we view <m>\xx\in\R^n</m> as an <m>n\times 1</m> column vector.
  </p>

  <p>
    Conversely, given any linear map <m>T:\R^n\to \R^m</m>,
    if we let <m>\basis{e}{n}</m> denote the standard basis of <m>\R^n</m>,
    then the matrix
    <me>
      A = \bbm T(\mathbf{e}_1) \amp T(\mathbf{e}_2) \amp \cdots \amp T(\mathbf{e}_n)\ebm
    </me>
    is such that <m>T=T_A</m>.
  </p>

  <p>
    We have already discussed the fact that this idea generalizes:
    given a linear transformation <m>T:V\to W</m>,
    where <m>V</m> and <m>W</m> are finite-dimensional vector spaces,
    it is possible to represent <m>T</m> as a matrix transformation.
  </p>

  <p>
    The representation depends on choices of bases for both <m>V</m> and <m>W</m>.
    Recall the definition of the coefficient isomorphism,
    from <xref ref="def-coefficient-iso">Definition</xref> in <xref ref="sec-isomorphism">Section</xref>.
    If <m>\dim V=n</m> and <m>\dim W=m</m>,
    this gives us isomorphisms <m>C_B:V\to \R^n</m> and <m>C_D:W\to \R^m</m>
    depending on the choice of a basis <m>B</m> for <m>V</m> and a basis <m>D</m> for <m>W</m>.
    These isomorphisms define a matrix transformation <m>T_A:\R^n\to \R^m</m>
    according to the diagram we gave in <xref ref="fig_transformation_matrix">Figure</xref>.
  </p>

  <p>
    We should stress one important point about the coefficient isomorphism, however.
    It depends on the choice of basis, but also on the <em>order</em> of the basis elements.
    Thus, we generally will work with an <em>ordered basis</em> in this chapter.
    That is, rather than simply thinking of our basis as a set,
    we will think of it as an ordered list.
    Order matters, since given a basis <m>B=\basis{e}{n}</m>,
    we rely on the fact that we can write any vector <m>\vv</m> uniquely as
    <me>
      \vv = c_1\mathbf{e}_1+\cdots +c_n\mathbf{e}_n
    </me>
    in order to make the assignment <m>C_B(\vv) = \bbm c_1\\\vdots \\c_n\ebm</m>.
  </p>

  <exercise>
    <statement>
      <p>
        Show that the coefficient isomorphism is, indeed,
        a linear isomorphism from <m>V</m> to <m>\R^n</m>.
      </p>
    </statement>
    <solution>
      <p>
        It's clear that <m>C_B(\zer)=\zer</m>,
        since the only way to write the zero vector in <m>V</m> in terms of <m>B</m>
        (or, indeed, any independent set) is to set all the scalars equal to zero.
      </p>

      <p>
        If we have two vectors <m>\vv,\ww</m> given by
        <md>
          <mrow>\vv \amp = a_1\mathbf{e}_1+\cdots + a_n\mathbf{e}_n </mrow>
          <mrow>\ww \amp = b_1\mathbf{e}_1+\cdots + b_n\mathbf{e}_n</mrow>
        </md>,
        then
        <me>
          \vv+\ww = (a_1+b_1)\mathbf{e}_1+\cdots + (a_n+b_n)\mathbf{e}_n
        </me>,
        so
        <md>
          <mrow>C_B(\vv+\ww) \amp = \bbm a_1+b_1\\\vdots \\ a_n+b_n\ebm </mrow>
          <mrow> \amp = \bbm a_1\\\vdots\\a_n\ebm +\bbm b_1\\\vdots \\b_n\ebm</mrow>
          <mrow>  \amp = C_B(\vv)+C_B(\ww)</mrow>
        </md>.
      </p>

      <p>
        Finally, for any scalar <m>c</m>, we have
        <md>
          <mrow>C_B(c\vv) \amp = C_B((ca_1)\mathbf{e}_1+\cdots +(ca_n)\mathbf{e}_n)</mrow>
          <mrow> \amp = \bbm ca_1\\\vdots \\ca_n\ebm</mrow>
          <mrow>  \amp =c\bbm a_1\\\vdots \\a_n\ebm</mrow>
          <mrow>  \amp =cC_B(\vv)</mrow>
        </md>.
      </p>

      <p>
        This shows that <m>C_B</m> is linear.
        To see that <m>C_B</m> is an isomorphism, we can simply note that <m>C_B</m>
        takes the basis <m>B</m> to the standard basis of <m>\R^n</m>.
        Alternatively, we can give the inverse: <m>C_B^{-1}:\R^n\to V</m> is given by
        <me>
          C_B^{-1}\bbm c_1\\\vdots \\c_n\ebm = c_1\mathbf{e}_1+\cdots +c_n\mathbf{e}_n
        </me>.
      </p>
    </solution>
  </exercise>

  <p>
    Given <m>T:V\to W</m> and coefficient isomorphisms <m>C_B:V\to \R^n, C_D:W\to \R^m</m>,
    the map <m>C_DTC_B^{-1}:\R^n\to \R^m</m> is a linear transformation,
    and the matrix of this transformation gives a representation of <m>T</m>.
    Explicitly, let <m>B = \basis{v}{n}</m> be an ordered basis for <m>V</m>,
    and let <m>D=\basis{w}{m}</m> be an ordered basis for <m>W</m>.
    Since <m>T(\vv_i)\in W</m> for each <m>\vv_i\in B</m>,
    there exist unique scalars <m>a_{ij}</m>, with <m>1\leq i\leq m</m>
    and <m>1\leq j\leq n</m> such that
    <me>
      T(\vv_j) = a_{1j}\ww_1+a_{2j}\ww_2+\cdots + a_{mj}\ww_m
    </me>
    for <m>j=1,\ldots, n</m>. This gives us the <m>m\times n</m> matrix <m>A = [a_{ij}]</m>.
    Notice that the first column of <m>A</m> is <m>C_D(T(\vv_1))</m>,
    the second column is <m>C_D(T(\vv_2))</m>, and so on.
  </p>

  <p>
    Given <m>\xx\in V</m>, write <m>\xx = c_1\vv_1+\cdots + c_n\vv_n</m>,
    so that <m>C_B(\xx) = \bbm c_1\\\vdots \\c_n\ebm</m>. Then
    <me>
      T_A(C_B(\xx)) = \bbm a_{11}\amp a_{12} \amp \cdots \amp a_{1n}\\
                           a_{21}\amp a_{22} \amp \cdots \amp a_{2n}\\
                           \vdots \amp \vdots \amp \ddots \amp \vdots\\
                           a_{m1}\amp a_{m2} \amp \cdots \amp a_{mn}\ebm\bbm c_1\\c_2\\ \vdots \\c_n\ebm
                           = \bbm a_{11}c_1+a_{12}c_2+\cdots +a_{1n}c_n\\
                                  a_{21}c_1+a_{22}c_2+\cdots +a_{2n}c_n\\
                                  \vdots\\
                                  a_{m1}c_1+a_{m2}c_2+\cdots +a_{mn}c_n\ebm
    </me>.
  </p>

  <p>
    On the other hand,
    <md>
      <mrow>T(\xx) \amp = T(c_1\vv_1+\cdots + c_n\vv_n) </mrow>
      <mrow> \amp = c_1T(\vv_1)+\cdots + c_nT(\vv_n)</mrow>
      <mrow> \amp = c_1(a_{11}\ww_1+\cdots + a_{m1}\ww_m)+\cdots c_n(a_{1n}\ww_1+\cdots + a_{mn}\ww_m)</mrow>
      <mrow> \amp = (c_1a_{11}+\cdots + c_na_{1n})\ww_1 + \cdots + (c_1a_{m1}+\cdots + c_na_{mn})\ww_m</mrow>
    </md>.
    Therefore,
    <me>
      C_D(T(\xx)) = \bbm c_1a_{11}+\cdots + c_na_{1n}\\ \vdots \\ c_1a_{m1}+\cdots + c_na_{mn}\ebm = T_A(C_B(\xx))
    </me>.
    Thus, we see that <m>C_DT = T_AC_B</m>, or <m>T_A = C_DTC_B^{-1}</m>, as expected.
  </p>

  <definition xml:id="def-transformation-matrix">
    <title>The matrix <m>M_{DB}(T)</m> of a linear map</title>

    <statement>
      <p>
        Let <m>V</m> and <m>W</m> be finite-dimensional vector spaces,
        and let <m>T:V\to W</m> be a linear map.
        Let <m>B=\basis{v}{n}</m> and <m>D=\basis{w}{m}</m> be ordered bases for <m>V</m> and <m>W</m>,
        respectively. Then the <term>matrix</term> <m>M_{DB}(T)</m> of <m>T</m> with respect to the bases <m>B</m> and <m>D</m>
        is defined by
        <me>
          M_{DB}(T) = \bbm C_D(T(\vv_1)) \amp C_D(T(\vv_2)) \amp \cdots \amp C_D(T(\vv_n))\ebm
        </me>.
      </p>
    </statement>
  </definition>

  <p>
    In other words, <m>A=M_{DB}(T)</m> is the unique <m>m\times n</m> matrix such that <m>C_DT = T_AC_B</m>.
    This gives the defining property
    <me>
      C_D(T(\vv)) = M_{DB}(T)C_B(\vv)  \text{ for all } \vv\in V
    </me>,
    as was demonstrated above.
  </p>

  <exercise>
    <statement>
      <p>
        Suppose <m>T:P_2(\R)\to \R^2</m> is given by
        <me>
          T(a+bx+cx^2) = (a+c,2b)
        </me>.
        Compute the matrix of <m>T</m> with respect to the bases
        <m>B = \{1,1-x,(1-x)^2\}</m> of <m>P_2(\R)</m> and
        <m>D = \{(1,0),(1,-1)\}</m> of <m>\R^2</m>.
      </p>
    </statement>
    <solution>
      <p>
        We have
        <md>
          <mrow>T(1) \amp = (1,0) = 1(1,0)+0(1,-1) </mrow>
          <mrow>T(1-x) \amp= (1,-2) = -1(1,0)+2(1,-1) </mrow>
          <mrow> T((1-x)^2) = T(1-2+x^2) \amp = (2, -4) = -2(1,0)+4(1,-1)</mrow>
        </md>.
        Thus,
        <md>
          <mrow>M_{DB}(T) \amp = \bbm C_D(T(1))\amp C_D(T(1-x)) \amp C_D(T((1-x)^2))\ebm</mrow>
          <mrow>\amp = \bbm 1\amp -1\amp -2\\0\amp 2\amp 4\ebm</mrow>
        </md>.
        To confirm, note that
        <md>
          <mrow>M_{DB}(T)C_B\amp (a+bx+cx^2)</mrow>
          <mrow> \amp = M_{DB}(T)C_B((a+b+c)-(b+2c)(1-x)+c(1-x)^2)</mrow>
          <mrow> \amp = \bbm 1\amp -1\amp -2\\0\amp 2\amp 4\ebm\bbm a+b+c\\ -b-2c\\c\ebm</mrow>
          <mrow> \amp \bbm (a+b+c)+(b+2c)-2c\\0-2(b+2c)+4c\ebm = \bbm a+2b+c\\-2b\ebm</mrow>
        </md>,
        while on the other hand,
        <md>
          <mrow>C_D(T(a+bx+cx^2)) \amp= C_D(a+c,2b)</mrow>
          <mrow>\amp = C_D((a+2b+c)(1,0)-2b(1,-1))</mrow>
          <mrow>\amp = \bbm a+2b+c\\-2b\ebm</mrow>
        </md>.

      </p>
    </solution>
  </exercise>

  <p>
    When we compute the matrix of a transformation with respect to a non-standard basis,
    we don't have to worry about how to write vectors in the domain in terms of that basis.
    Instead, we simply plug the basis vectors into the transformation,
    and then determine how to write the output in terms of the basis of the codomain.
    However, if we want to <em>use</em> this matrix to compute values of <m>T:V\to W</m>,
    then we need a systematic way of writing elements of <m>V</m> in terms of the given basis.
  </p>

  <example>
    <title>Working with the matrix of a transformation</title>


    <statement>
      <p>
        Let <m>T:P_2(\R)\to \R^2</m> be a linear transformation whose matrix is given by
        <me>
          M(T) = \bbm 3\amp 0 \amp 3\\-1\amp -2\amp 2\ebm
        </me>
        with respect to the ordered bases <m>B = \{1+x, 2-x, 2x+x^2\}</m> of  <m>P_2(\R)</m>
        and <m>D = \{(0,1),(-1,1)\}</m> of <m>\R^2</m>. Find the value of <m>T(2+3x-4x^2)</m>.
      </p>
    </statement>
    <solution>
      <p>
        We need to write the input <m>2+3x-4x^2</m> in terms of the basis <m>B</m>.
        This amounts to solving the system of equations given by
        <me>
          a(1+x)+b(2-x)+c(2x+x^2)=2+3x-4x^2
        </me>.
        Of course, we can easily set up and solve this system,
        but let's try to be systematic, and obtain a more useful result for future problems.
        Since we can easily determine how to write any polynomial in terms of the standard basis <m>\{1,x,x^2\}</m>,
        it suffices to know how to write these three polynomials in terms of our basis.
      </p>

      <p>
        At first, this seems like more work. After all, we now have three systems to solve:
        <md>
          <mrow>a_1(x+1)+b_1(2-x)+c_1(2x+x^2) \amp =1</mrow>
          <mrow>a_2(x+1)+b_2(2-x)+c_2(2x+x^2) \amp =x</mrow>
          <mrow>a_3(x+1)+b_3(2-x)+c_3(2x+x^2) \amp =x^2</mrow>
        </md>.
        However, all three systems have the same coefficient matrix,
        so we can solve them simultaneously, by adding three <q>constants</q>
        columns to our augmented matrix.
      </p>

      <p>
        We get the matrix
        <me>
          \left[\begin{matrix}1\amp 2\amp 0\\1\amp -1\amp 2\\0\amp 0\amp 1\end{matrix}
          \right\rvert\left.\begin{matrix}1\amp 0\amp 0\\0\amp 1\amp 0\\0\amp 0\amp 1\end{matrix}\right]
        </me>.
        But this is exactly the augmented matrix we'd right down if we were trying to find the inverse of the matrix
        <me>
          P=\bbm 1\amp 2\amp 0\\1\amp -1\amp 2\\0\amp 0\amp 1\ebm
        </me>
        whose columns are the coefficient representations of our given basis vectors in terms of the standard basis.
      </p>

      <p>
        To compute <m>P^{-1}</m>, we use the computer:
      </p>

      <sage>
        <input>
          from sympy import Matrix, init_printing
          init_printing()
          P = Matrix(3,3,[1,2,0,1,-1,2,0,0,1])
          P**-1
        </input>
        <output>
          \[\bbm \frac13\amp \frac23\amp -\frac43\\ \frac13\amp -\frac13 \amp \frac23\\0\amp 0\amp 1\ebm\]
        </output>
      </sage>

      <p>
        Next, we find <m>M(T)P^{-1}</m>:
      </p>

      <sage>
        <input>
          M = Matrix(2,3,[3,0,3,-1,-2,2])
          v = Matrix(3,1,[2,3,-4])
          M*P**-1
        </input>
        <output>
          \[\bbm 1\amp 2\amp -1\\-1\amp 0\amp 2\ebm\]
        </output>
      </sage>

      <p>
        This matrix first converts the coefficient vector for a polynomial <m>p(x)</m>
        with respect to the standard basis into the coefficient vector for our given basis <m>B</m>,
        and then multiplies by the matrix representing our transformation.
        The result will be the coefficient vector for <m>T(p(x))</m> with respect to the basis <m>D</m>.
      </p>

      <p>
        The polynomial <m>p(x) = 2+3x-4x^2</m> has coefficient vector <m>\bbm 2\\3\\-4\ebm</m>
        with respect to the standard basis. We find that <m>M(T)P^{-1}\bbm 2\\3\\-4\ebm = \bbm 12\\-10\ebm</m>:
      </p>

      <sage>
        <input>
          M = Matrix(2,3,[3,0,3,-1,-2,2])
          v = Matrix(3,1,[2,3,-4])
          (M*P**-1)*v
        </input>
        <output>
          \[\bbm 12\\-10\ebm\]
        </output>
      </sage>

      <p>
        The coefficients <m>12</m> and <m>-10</m> are the coefficients of <m>T(p(x))</m>
        with repsect to the basis <m>D</m>. Thus,
        <me>
          T(2+3x-4x^2) = 12(0,1)-10(-1,1) = (10,2)
        </me>.
        Note that in the last step we gave the <q>simplified</q> answer <m>(10,2)</m>,
        which is simplified primarily in that it is expressed with respect to the standard basis.
      </p>

      <p>
        Note that we can also introduce the matrix <m>Q = \bbm 0\amp -1\\1\amp 1\ebm</m>
        whose columns are the coefficient vectors of the vectors in the basis <m>D</m>
        with respect to the standard basis.
        The effect of multiplying by <m>Q</m> is to convert from coefficients with respect to <m>D</m>
        into a coefficient vector with respect to the standard basis.
        We can then write a new matrix <m>\hat{M}(T) = QM(T)P^{-1}</m>;
        this new matrix is now the matrix representation of <m>T</m> with respect to the
        <em>standard</em> bases of <m>P_2(\R)</m> and <m>\R^2</m>.
      </p>

      <sage>
        <input>
          Q = Matrix(2,2,[0,-1,1,1])
          Q*M*P**-1
        </input>
        <output>
          \[\bbm 1\amp 0\amp -2\\0\amp 2\amp 1\ebm\]
        </output>
      </sage>

      <p>
        We check that
        <me>
          \hat{M}(T)\bbm 2\\3\\-4\ebm = \bbm 10\\2\ebm
        </me>,
        as before.
      </p>

      <sage>
        <input>
          (Q*M*P**-1)*v
        </input>
        <output>
          \[\bbm 10\\2 \ebm\]
        </output>
      </sage>

      <p>
        We find that <m>\tilde{M}(T) = \bbm 1\amp 0\amp -2\\0\amp 2\amp 1\ebm</m>.
        This lets us determine that for a general polynomial <m>p(x) = a+bx+cx^2</m>,
        <me>
          \hat{M}(T)\bbm a\\b\\c\ebm = \bbm a-2c\\2b+c\ebm
        </me>,
        and therefore, our original transformation must have been
        <me>
          T(a+bx+cx^2)=(a-2c,2b+c)
        </me>.

      </p>
    </solution>
  </example>

  <p>
    The previous example illustrated some important observations that are true in general.
    We won't give the general proof, but we sum up the results in a theorem.
  </p>

  <theorem xml:id="thm-change-basis-transformation">
    <statement>
      <p>
        Suppose <m>T:V\to W</m> is a linear transformation,
        and suppose <m>M_0 = M_{D_0B_0}(T)</m> is the matrix of <m>T</m> with respect to bases <m>B_0</m> of <m>V</m> and <m>D_0</m> of <m>W</m>.
        Let <m>B_1=\basis{v}{n}</m> and <m>D_1=\basis{w}{m}</m> be any other choice of basis for <m>V</m> and <m>W</m>, respectively.
        Let
        <md>
          <mrow>P \amp =\bbm C_{B_0}(\vv_1) \amp C_{B_0}(\vv_2) \amp \cdots \amp C_{B_0}(\vv_n)\ebm</mrow>
          <mrow>Q \amp =\bbm C_{D_0}(\ww_1) \amp C_{D_0}(\ww_2) \amp \cdots \amp C_{DB_0}(\ww_n)\ebm</mrow>
        </md>
        be matrices whose columns are the coefficient vectors of the vectors in <m>B_1,D_1</m> with respect to <m>B_0,D_0</m>.
        Then the matrix of <m>T</m> with respect to the bases <m>B_1</m> and <m>D_1</m> is
        <me>
          M_{D_0B_0}(T) = QM_{D_1B_1}(T)P^{-1}
        </me>.
      </p>
    </statement>
  </theorem>

  <p>
    The relationship between the different maps is illustrated in <xref ref="fig-basis-cube"/> below.
    In this figure, the maps <m>V\to V</m> and <m>W\to W</m> are the identity maps,
    corresponding to representing the same vector with respect to two different bases.
    The vertical arrows are the coefficient isomorphisms <m>C_{B_0},C_{B_1},C_{D_0},C_{D_1}</m>.
  </p>

  <p>
    In the <init>HTML</init> version of the book, you can click and drag to rotate the figure below.
  </p>

  <figure xml:id="fig-basis-cube">
    <caption>Diagramming matrix of a transformation with respect to two different choices of basis</caption>
    <!-- <interactive xml:id="geogebra-basis-cube" platform="geogebra" width="67%" aspect="1:1">
      <slate xml:id="basis-cube" surface="geogebra" source="images/basis_cube.ggb" aspect="1:1"/>
      <static>
        <image xml:id="img-basis-cube" width="67%" source="images/basis_cube.pdf"/>
      </static>
    </interactive> -->
    <image xml:id="img-basis-cube" width="60%">
      <description></description>
      <asymptote>
        import three;
        usepackage("amssymb");

        currentprojection=orthographic(8,3,2,center=true);

        size(10cm);
        size3(6cm,10cm,16cm);

        draw(unitbox);

        dot(unitbox, 6+blue);

        label("$\mathbb{R}^n$",(0,-0.01,0),W);
        label("$\mathbb{R}^n$",(1,0,0),SW);
        label("$\mathbb{R}^m$",(0,1,0),SE);
        label("$\mathbb{R}^m$",(1,1,0),SE);
        draw("$C_{B_1}$",(0,0,1)--(0,0,0),arrow=Arrow3(),1+black);
        draw("$C_{B_2}$",(1,0,1)--(1,0,0),arrow=Arrow3(),1+black);
        draw("$C_{D_1}$",(0,1,1)--(0,1,0),arrow=Arrow3(),1+black);
        draw("$C_{D_2}$",(1,1,1)--(1,1,0),arrow=Arrow3(),1+black);
        draw("$M_{D_1B_1}(T)$",(0,0,0)--(0,1,0),arrow=Arrow3(),1+black);
        draw("$M_{D_2B_2}(T)$",(1,0,0)--(1,1,0),arrow=Arrow3(),1+black);
        //draw("$I$",(0,0,1)--(1,0,1),arrow=Arrow3(),1+black);
        //draw("$I$",(0,1,1)--(1,1,1),arrow=Arrow3(),1+black);
        //draw("$P_{B_1\leftarrow B_2}$",(0,0,0)--(1,0,0),arrow=Arrow3(),1+black);
        //draw("$P_{D_1\leftarrow D_2}$",(0,1,0)--(1,1,0),arrow=Arrow3(),1+black);
        label("$V$",(0,0,1),NW);
        label("$V$",(1,0,1),NW);
        label("$W$",(0,1,1),NE);
        label("$W$",(1,1,1),ESE);
        draw("$T$",(1,0,1)--(1,1,1),arrow=Arrow3(),1+black);
        draw("$T$",(0,0,1)--(0,1,1),arrow=Arrow3(),1+black);
      </asymptote>
    </image>
  </figure>

  <p>
    We generally apply <xref ref="thm-change-basis-transformation"/> in the case that <m>B_0,D_0</m>
    are the <em>standard</em> bases for <m>V,W</m>, since in this case,
    the matrices <m>M_0, P, Q</m> are easy to determine,
    and we can use a computer to calculate <m>P^{-1}</m> and the product <m>QM_0P^{-1}</m>.
  </p>

  <exercise>
    <statement>
      <p>
        Suppose <m>T:M_{22}(\R)\to P_2(\R)</m> has the matrix
        <me>
          M_{DB}(T) = \bbm 2\amp -1\amp 0\amp 3\\0\amp 4\amp -5\amp 1\\-1\amp 0\amp 3\amp -2\ebm
        </me>
        with respect to the bases
        <me>
          B = \left\{\bbm 1\amp 0\\0\amp 0\ebm, \bbm 0\amp 1\\0\amp 1\ebm, \bbm 0\amp 1\\1\amp 0\ebm, \bbm 1\amp 0\\0\amp 1\ebm\right\}
        </me>
        of <m>M_{22}(\R)</m> and <m>D=\{1,x,x^2\}</m> of <m>P_2(\R)</m>.
        Determine a formula for <m>T</m> in terms of a general input <m>X=\bbm a\amp b\\c\amp d\ebm</m>.
      </p>
    </statement>
    <solution>
      <p>
        We must first write our general input in terms of the given basis.
        With respect to the standard basis
        <me>
          B_0 = \left\{\bbm 1\amp 0\\0\amp 0\ebm, \bbm 0\amp 1\\0\amp 0\ebm, \bbm 0\amp 0\\1\amp 0\ebm, \bbm 0\amp 0\\0\amp 1\ebm\right\}
        </me>,
        we have the matrix <m>P = \bbm 1\amp 0\amp 0\amp 1\\0\amp 1\amp 1\amp 0\\0\amp 0\amp 1\amp 0\\0\amp 1\amp 0\amp 1\ebm</m>,
        representing the change from the basis <m>B</m> the basis <m>B_0</m>.
        The basis <m>D</m> of <m>P_2(\R)</m> is already the standard basis,
        so we need the matrix <m>M_{DB}(T)P^{-1}</m>:
      </p>

      <sage>
        <input>
          from sympy import Matrix, init_printing
          init_printing()
          M = Matrix(3,4,[2,-1,0,3,0,4,-5,1,-1,0,3,-2])
          P = Matrix(4,4,[1,0,0,1,0,1,1,0,0,0,1,0,0,1,0,1])
          M*P**-1
        </input>
        <output>
          \[\bbm 2\amp -2\amp 2\amp 1\\0\amp 3\amp -8\amp 1\\-1\amp 1\amp 2\amp -1\ebm\]
        </output>
      </sage>

      <p>
        For a matrix <m>X = \bbm a\amp b\\c\amp d\ebm</m> we find
        <me>
          M_{DB}(T)P^{-1}C_{B_0}(X)=\bbm 2\amp -2\amp 2\amp 1\\0\amp 3\amp -8\amp 1\\-1\amp 1\amp 2\amp -1\ebm\bbm a\\b\\c\\d\ebm =
          \bbm 2a-2b+2c+d\\3b-8c+d\\-a+b+2c-d\ebm
        </me>.
        But this is equal to <m>C_D(T(X))</m>, so
        <md>
          <mrow>T\left(\bbm a\amp b\\c\amp d\ebm\right) \amp = C_D^{-1}\bbm 2a-2b+2c+d\\3b-8c+d\\-a+b+2c-d\ebm</mrow>
          <mrow>\amp = (2a-2b+2c+d)+(3b-8c+d)x+(-a+b+2c-d)x^2</mrow>
        </md>.
      </p>
    </solution>
  </exercise>

  <p>
    In textbooks such as Sheldon Axler's <em>Linear Algebra Done Right</em> that focus primarily on linear transformations,
    the above construction of the matrix of a transformation with respect to choices of bases can be used as a primary motivation for introducing matrices,
    and determining their algebraic properties. In particular, the rule for matrix multiplication, which can seem peculiar at first,
    can be seen as a consequence of the composition of linear maps.
  </p>

  <theorem xml:id="thm-matrix-multiplication">
    <statement>
      <p>
        Let <m>U,V,W</m> be finite-dimensional vectors spaces,
        with ordered bases <m>B_1,B_2,B_3</m>, respectively.
        Let <m>T:U\to V</m> and <m>S:V\to W</m> be linear maps. Then
        <me>
          M_{B_3B_1}(ST) = M_{B_3B_2}(S)M_{B_2B_1}(T)
        </me>.
      </p>
    </statement>
    <proof>
      <p>
        Let <m>\xx\in U</m>. Then <m>C_{B_3}(ST(\xx)) = M_{B_3B_1}(ST)C_{B_1}(\xx)</m>.
        On the other hand,
        <md>
          <mrow> M_{B_3B_2}(S)M_{B_2B_1}(T)C_{B_1}(\xx) \amp  = M_{B_3B_2}(S)(C_{B_2}(T(\xx)))</mrow>
          <mrow> \amp = C_{B_3}(S(T(\xx))) = C_{B_3}(ST(\xx))</mrow>
        </md>.
        Since <m>C_{B_3}</m> is invertible, the result follows.
      </p>
    </proof>

  </theorem>

  <p>
    Being able to express a general linear transformation in terms of a matrix is useful,
    since questions about linear transformations can be converted into questions about matrices that we already know how to solve.
    In particular,
    <ul>
      <li>
        <p>
          <m>T:V\to W</m> is an isomorphism if and only if <m>M_{DB}(T)</m> is invertible for some
          (and hence, all) choice of bases <m>B</m> of <m>V</m> and <m>D</m> of <m>W</m>.
        </p>
      </li>

      <li>
        <p>
          The rank of <m>T</m>  is equal to the rank of <m>M_{DB}(T)</m> (and this does not depend on the choice of basis).
        </p>
      </li>

      <li>
        <p>
          The kernel of <m>T</m> is isomorphic to the nullspace of <m>M_{DB}(T)</m>.
        </p>
      </li>
    </ul>
  </p>

  <p>
    Next, we will want to look at two topics in particular.
    First, if <m>T:V\to V</m> is a linear operator, then it makes sense to consider the matrix <m>M_B(T)=M_{BB}(T)</m>
    obtained by using the same basis for both domain and codomain.
    Second, we will want to know how this matrix changes if we change the choice of basis.
  </p>
</section>
